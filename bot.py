import os, json, hashlib, asyncio, logging, re, random, io, time
from pathlib import Path
from datetime import datetime, timezone, timedelta
from bs4 import BeautifulSoup
import feedparser, httpx, pytz

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_OK = True
except ImportError:
    PIL_OK = False

try:
    from hazm import Normalizer as HazmNorm
    _hazm = HazmNorm()
    def nfa(t): return _hazm.normalize(t or "")
except ImportError:
    def nfa(t): return re.sub(r' +', ' ', (t or "").replace("ÙŠ","ÛŒ").replace("Ùƒ","Ú©")).strip()

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
log = logging.getLogger("WarBot")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BOT_TOKEN      = os.environ.get("BOT_TOKEN", "")
CHANNEL_ID     = os.environ.get("CHANNEL_ID", "")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

SEEN_FILE         = "seen.json"
TITLE_HASH_FILE   = "title_hashes.json"
GEMINI_STATE_FILE = "gemini_state.json"
FLIGHT_ALERT_FILE = "flight_alerts.json"

MAX_NEW_PER_RUN    = 20     # Ø­Ø¯Ø§Ú©Ø«Ø± Ø®Ø¨Ø± per run â€” Ø§ÙˆÙ„ÙˆÛŒØª Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†
TW_HANDLES_PER_RUN = 20    # handleâ€ŒÙ‡Ø§ÛŒ ØªÙˆÛŒÛŒØªØ± per run (Ø§Ø² Û´Û·)
MAX_MSG_LEN        = 4096
SEND_DELAY         = 0.8   # Ø«Ø§Ù†ÛŒÙ‡ Ø¨ÛŒÙ† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
CUTOFF_HOURS       = 4
TG_CUTOFF_HOURS    = 2
JACCARD_THRESHOLD  = 0.38
RSS_TIMEOUT        = 8.0
TG_TIMEOUT         = 10.0
TW_TIMEOUT         = 9.0
HIGH_URGENCY_ICONS = {"ğŸ’€","ğŸ”´","ğŸ’¥"}
MAX_ARTICLE_LEN    = 3000
MAX_TITLE_LEN      = 600

# Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ú©Ø±Ùˆ Ø¨Ø±Ø§ÛŒ dedup
_VIOLENCE_CODES  = {"MSL","AIR","ATK","KIA","DEF","EXP"}
_POLITICAL_CODES = {"THR","DIP","SAN","NUC","SPY","STM"}
TEHRAN_TZ         = pytz.timezone("Asia/Tehran")

# â”€â”€ Ø§Ù…ØªÛŒØ§Ø² Ø§Ù‡Ù…ÛŒØª Ø®Ø¨Ø± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ø®Ø¨Ø±Ù‡Ø§ÛŒÛŒ Ø¨Ø§ score â‰¥ RICH_CARD_THRESHOLD â†’ Ú©Ø§Ø±Øª ØªÙØµÛŒÙ„ÛŒ (article fetch)
RICH_CARD_THRESHOLD = 7
BREAKING_KEYWORDS   = [
    "breaking","urgent","alert","just in","developing","confirmed",
    "explosion","airstrike","killed","dead","war","attack","strike",
    "nuclear","bomb","missile","assassinated","coup","invasion",
    "Ø­Ù…Ù„Ù‡","Ú©Ø´ØªÙ‡","Ø§Ù†ÙØ¬Ø§Ø±","Ø´Ù‡ÛŒØ¯","Ù…ÙˆØ´Ú©","Ø§Ø¹Ù„Ø§Ù… Ø¬Ù†Ú¯","ØªÙ‡Ø§Ø¬Ù…","ÙÙˆØ±ÛŒ","Ø®Ø¨Ø± ÙÙˆØ±ÛŒ",
]
IMPORTANCE_BOOST = {
    "ğŸ’€": 4, "ğŸ”´": 3, "ğŸ’¥": 3, "ğŸš€": 3, "â˜¢ï¸": 3,
    "âœˆï¸": 2, "ğŸš¢": 2, "ğŸ›¡ï¸": 2, "ğŸ•µï¸": 2,
    "ğŸ”¥": 1, "ğŸ’°": 1, "âš ï¸": 1,
}

def calc_importance(title: str, body: str, sentiment_icons: list, stype: str) -> int:
    """
    Ø§Ù…ØªÛŒØ§Ø² Ø§Ù‡Ù…ÛŒØª Û°-Û±Û°:
    3+ Ø¨Ø±Ø§ÛŒ sentiment icons
    2+ Ø¨Ø±Ø§ÛŒ breaking keywords
    1+ Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø³Ù…ÛŒ (tw=CENTCOM/IDF/â€¦)
    """
    txt = (title + " " + body).lower()
    score = sum(IMPORTANCE_BOOST.get(ic, 0) for ic in sentiment_icons)
    if any(k in txt for k in BREAKING_KEYWORDS):
        score += 2
    if stype in ("tw",) and score > 0:   # ØªÙˆÛŒÛŒØª Ø±Ø³Ù…ÛŒ ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯
        score += 1
    return min(score, 10)

def get_cutoff(h=None):
    return datetime.now(timezone.utc) - timedelta(hours=h or CUTOFF_HOURS)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ‡®ğŸ‡·  Ø§ÛŒØ±Ø§Ù†  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IRAN_FEEDS = [
    {"n":"ğŸ‡®ğŸ‡· IRNA English",       "u":"https://en.irna.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Mehr News EN",        "u":"https://en.mehrnews.com/rss"},
    {"n":"ğŸ‡®ğŸ‡· Tasnim News EN",      "u":"https://www.tasnimnews.com/en/rss"},
    {"n":"ğŸ‡®ğŸ‡· Fars News EN",        "u":"https://www.farsnews.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Press TV",            "u":"https://www.presstv.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· ISNA English",        "u":"https://en.isna.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Tehran Times",        "u":"https://www.tehrantimes.com/rss"},
    {"n":"ğŸ‡®ğŸ‡· Iran Daily",          "u":"https://www.iran-daily.com/rss"},
    {"n":"ğŸ‡®ğŸ‡· Iran Front Page",     "u":"https://ifpnews.com/feed"},
    {"n":"ğŸ‡®ğŸ‡· Iran International",  "u":"https://www.iranintl.com/en/rss"},
    {"n":"ğŸ‡®ğŸ‡· Radio Farda",         "u":"https://www.radiofarda.com/api/zoyqvpemr"},
    {"n":"ğŸ‡®ğŸ‡· Iran Wire EN",        "u":"https://iranwire.com/en/feed/"},
    {"n":"ğŸ‡®ğŸ‡· Kayhan London",       "u":"https://kayhan.london/feed/"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ ØªØ³Ù†ÛŒÙ…",      "u":"https://www.tasnimnews.com/fa/rss/feed/0/8/0"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ù…Ù‡Ø±",         "u":"https://www.mehrnews.com/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø§ÛŒØ±Ù†Ø§",       "u":"https://www.irna.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø§ÛŒØ³Ù†Ø§",       "u":"https://www.isna.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ ÙØ§Ø±Ø³",        "u":"https://www.farsnews.ir/rss/fa"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¯Ø§Ù†Ø´Ø¬Ùˆ",      "u":"https://snn.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ù…ÛŒØ²Ø§Ù†",        "u":"https://www.mizanonline.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ø®Ø¨Ø±Ù†Ú¯Ø§Ø±Ø§Ù†",      "u":"https://www.yjc.ir/fa/rss/allnews"},
    {"n":"ğŸ‡®ğŸ‡· Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ†",            "u":"https://www.khabaronline.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø§Ù†ØªØ®Ø§Ø¨",                "u":"https://www.entekhab.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ù…Ø´Ø±Ù‚ Ù†ÛŒÙˆØ²",             "u":"https://www.mashreghnews.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· ØªØ§Ø¨Ù†Ø§Ú©",                "u":"https://www.tabnak.ir/fa/rss/allnews"},
    {"n":"ğŸ‡®ğŸ‡· ÙØ±Ø§Ø±Ùˆ",                 "u":"https://fararu.com/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø¢ÙØªØ§Ø¨ Ù†ÛŒÙˆØ²",            "u":"https://www.aftabnews.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø¹ØµØ± Ø§ÛŒØ±Ø§Ù†",             "u":"https://www.asriran.com/fa/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø¯ÛŒÙ¾Ù„Ù…Ø§Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ",       "u":"https://www.irdiplomacy.ir/fa/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø¯ÙØ§Ø¹ Ù¾Ø±Ø³",             "u":"https://www.defapress.ir/fa/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø³Ù¾Ø§Ù‡ Ù†ÛŒÙˆØ²",             "u":"https://www.sepahnews.com/rss"},
    {"n":"ğŸ‡®ğŸ‡· ØµØ¯Ø§ÛŒ Ø§Ø±ØªØ´",            "u":"https://arteshara.ir/fa/rss"},
    {"n":"ğŸ‡®ğŸ‡· Ø¢Ù†Ø§ Ø®Ø¨Ø±",               "u":"https://www.ana.ir/rss"},
    {"n":"ğŸ‡®ğŸ‡· GNews Ø¬Ù†Ú¯ Ø§ÛŒØ±Ø§Ù† FA",   "u":"https://news.google.com/rss/search?q=Ø§ÛŒØ±Ø§Ù†+Ø§Ø³Ø±Ø§ÛŒÛŒÙ„+Ø¬Ù†Ú¯+Ø­Ù…Ù„Ù‡&hl=fa&gl=IR&ceid=IR:fa&num=15"},
    {"n":"ğŸ‡®ğŸ‡· GNews Ø³Ù¾Ø§Ù‡ Ù…ÙˆØ´Ú© FA",   "u":"https://news.google.com/rss/search?q=Ø³Ù¾Ø§Ù‡+Ù…ÙˆØ´Ú©+Ø­Ù…Ù„Ù‡+Ø§Ø³Ø±Ø§ÛŒÛŒÙ„&hl=fa&gl=IR&ceid=IR:fa&num=15"},
    {"n":"ğŸ‡®ğŸ‡· GNews IRGC EN",        "u":"https://news.google.com/rss/search?q=IRGC+Iran+Israel+attack+war&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡®ğŸ‡· GNews Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒ",        "u":"https://news.google.com/rss/search?q=Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒ+Ø¨ÛŒØ§Ù†ÛŒÙ‡+Ø¬Ù†Ú¯&hl=fa&gl=IR&ceid=IR:fa&num=10"},
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ‡®ğŸ‡±  Ø§Ø³Ø±Ø§ÛŒÛŒÙ„  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ISRAEL_FEEDS = [
    {"n":"ğŸ‡®ğŸ‡± Jerusalem Post",       "u":"https://www.jpost.com/rss/rssfeedsheadlines.aspx"},
    {"n":"ğŸ‡®ğŸ‡± J-Post Military",      "u":"https://www.jpost.com/Rss/RssFeedsIsraelNews.aspx"},
    {"n":"ğŸ‡®ğŸ‡± Times of Israel",      "u":"https://www.timesofisrael.com/feed/"},
    {"n":"ğŸ‡®ğŸ‡± TOI Iran",             "u":"https://www.timesofisrael.com/topic/iran/feed/"},
    {"n":"ğŸ‡®ğŸ‡± Israel Hayom EN",      "u":"https://www.israelhayom.com/feed/"},
    {"n":"ğŸ‡®ğŸ‡± Arutz Sheva",          "u":"https://www.israelnationalnews.com/rss.aspx"},
    {"n":"ğŸ‡®ğŸ‡± i24 News",             "u":"https://www.i24news.tv/en/rss"},
    {"n":"ğŸ‡®ğŸ‡± All Israel News",      "u":"https://www.allisrael.com/feed"},
    {"n":"ğŸ‡®ğŸ‡± Israel Defense",       "u":"https://www.israeldefense.co.il/en/rss.xml"},
    {"n":"ğŸ‡®ğŸ‡± Begin-Sadat BESA",     "u":"https://besacenter.org/feed/"},
    {"n":"ğŸ‡®ğŸ‡± Alma Research",        "u":"https://www.alma-org.com/feed/"},
    {"n":"ğŸ‡®ğŸ‡± Haaretz GNews",        "u":"https://news.google.com/rss/search?q=site:haaretz.com+Iran+military+war&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡®ğŸ‡± Ynet GNews",           "u":"https://news.google.com/rss/search?q=site:ynetnews.com+Iran+military&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡®ğŸ‡± N12 GNews",            "u":"https://news.google.com/rss/search?q=site:mako.co.il+Iran+Israel+war&hl=iw-IL&gl=IL&ceid=IL:iw"},
    {"n":"ğŸ‡®ğŸ‡± Kan GNews",            "u":"https://news.google.com/rss/search?q=site:kan.org.il+Iran&hl=iw-IL&gl=IL&ceid=IL:iw"},
    {"n":"ğŸ‡®ğŸ‡± Netanyahu Iran GNews", "u":"https://news.google.com/rss/search?q=Netanyahu+Iran+attack+order+war&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡®ğŸ‡± IDF Iran GNews",       "u":"https://news.google.com/rss/search?q=IDF+operation+Iran+strike+missile&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡®ğŸ‡± Mossad Iran GNews",    "u":"https://news.google.com/rss/search?q=Mossad+Iran+covert+operation&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡®ğŸ‡± Iron Dome GNews",      "u":"https://news.google.com/rss/search?q=Iron+Dome+Arrow+missile+intercept+Iran&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡®ğŸ‡± Barak Ravid GNews",    "u":"https://news.google.com/rss/search?q=%22Barak+Ravid%22+Iran+Israel&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡®ğŸ‡± Yossi Melman GNews",   "u":"https://news.google.com/rss/search?q=%22Yossi+Melman%22+Iran+Mossad&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡®ğŸ‡± Hezbollah Israel",     "u":"https://news.google.com/rss/search?q=Hezbollah+attack+Israel+IDF&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡®ğŸ‡± IAF Strike Iran",      "u":"https://news.google.com/rss/search?q=Israeli+Air+Force+IAF+strike+Iran&hl=en-US&gl=US&ceid=US:en"},
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ‡ºğŸ‡¸  Ø¢Ù…Ø±ÛŒÚ©Ø§  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USA_FEEDS = [
    {"n":"ğŸ‡ºğŸ‡¸ AP Top News",          "u":"https://feeds.apnews.com/rss/apf-topnews"},
    {"n":"ğŸ‡ºğŸ‡¸ AP World",             "u":"https://feeds.apnews.com/rss/apf-WorldNews"},
    {"n":"ğŸ‡ºğŸ‡¸ Reuters World",        "u":"https://feeds.reuters.com/reuters/worldNews"},
    {"n":"ğŸ‡ºğŸ‡¸ Reuters Middle East",  "u":"https://feeds.reuters.com/reuters/MEonlineHeadlines"},
    {"n":"ğŸ‡ºğŸ‡¸ Bloomberg Politics",   "u":"https://feeds.bloomberg.com/politics/news.rss"},
    {"n":"ğŸ‡ºğŸ‡¸ WSJ World",            "u":"https://feeds.a.dj.com/rss/RSSWorldNews.xml"},
    {"n":"ğŸ‡ºğŸ‡¸ CNN Middle East",      "u":"http://rss.cnn.com/rss/edition_meast.rss"},
    {"n":"ğŸ‡ºğŸ‡¸ CNN World",            "u":"http://rss.cnn.com/rss/edition_world.rss"},
    {"n":"ğŸ‡ºğŸ‡¸ Fox News World",       "u":"https://moxie.foxnews.com/google-publisher/world.xml"},
    {"n":"ğŸ‡ºğŸ‡¸ Politico Defense",     "u":"https://rss.politico.com/defense.xml"},
    {"n":"ğŸ‡ºğŸ‡¸ Foreign Policy",       "u":"https://foreignpolicy.com/feed/"},
    {"n":"ğŸ‡ºğŸ‡¸ Pentagon DoD",         "u":"https://www.defense.gov/DesktopModules/ArticleCS/RSS.ashx?ContentType=1&Site=945&max=10"},
    {"n":"ğŸ‡ºğŸ‡¸ USNI News",            "u":"https://news.usni.org/feed"},
    {"n":"ğŸ‡ºğŸ‡¸ Breaking Defense",     "u":"https://breakingdefense.com/feed/"},
    {"n":"ğŸ‡ºğŸ‡¸ Defense News",         "u":"https://www.defensenews.com/arc/outboundfeeds/rss/"},
    {"n":"ğŸ‡ºğŸ‡¸ Military Times",       "u":"https://www.militarytimes.com/arc/outboundfeeds/rss/"},
    {"n":"ğŸ‡ºğŸ‡¸ The War Zone",         "u":"https://www.twz.com/feed"},
    {"n":"ğŸ‡ºğŸ‡¸ War on Rocks",         "u":"https://warontherocks.com/feed/"},
    {"n":"ğŸ‡ºğŸ‡¸ NYT Iran GNews",       "u":"https://news.google.com/rss/search?q=site:nytimes.com+Iran+Israel+war+military&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡ºğŸ‡¸ WaPo Iran GNews",      "u":"https://news.google.com/rss/search?q=site:washingtonpost.com+Iran+Israel+military&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡ºğŸ‡¸ US Strike Iran GNews", "u":"https://news.google.com/rss/search?q=United+States+strike+bomb+Iran+military&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡ºğŸ‡¸ US Navy Iran GNews",   "u":"https://news.google.com/rss/search?q=US+Navy+carrier+Iran+Persian+Gulf&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡ºğŸ‡¸ Trump Iran GNews",     "u":"https://news.google.com/rss/search?q=Trump+Iran+attack+bomb+military&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"ğŸ‡ºğŸ‡¸ CENTCOM GNews",        "u":"https://news.google.com/rss/search?q=CENTCOM+Iran+Iraq+military+operation&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ‡ºğŸ‡¸ Farnaz Fassihi",       "u":"https://news.google.com/rss/search?q=%22Farnaz+Fassihi%22+Iran+nuclear&hl=en-US&gl=US&ceid=US:en"},
    {"n":"ğŸ” Long War Journal",      "u":"https://www.longwarjournal.org/feed"},
    {"n":"ğŸ” OSINTdefender",         "u":"https://osintdefender.com/feed/"},
    {"n":"ğŸ” Bellingcat",            "u":"https://www.bellingcat.com/feed/"},
    {"n":"âš ï¸ IAEA Iran GNews",       "u":"https://news.google.com/rss/search?q=IAEA+Iran+nuclear+uranium+bomb&hl=en-US&gl=US&ceid=US:en&num=15"},
    {"n":"âš ï¸ Red Sea Houthi GNews",  "u":"https://news.google.com/rss/search?q=Houthi+Iran+Red+Sea+attack+US&hl=en-US&gl=US&ceid=US:en&num=15"},
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ›ï¸  Ø³ÙØ§Ø±ØªØ®Ø§Ù†Ù‡â€ŒÙ‡Ø§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMBASSY_FEEDS = [
    {"n":"ğŸ›ï¸ US Virtual Embassy",   "u":"https://ir.usembassy.gov/feed/"},
    {"n":"ğŸ›ï¸ US State Travel",      "u":"https://travel.state.gov/content/travel/en/traveladvisories/traveladvisories.html.rss"},
    {"n":"ğŸ›ï¸ UK FCDO Iran",         "u":"https://www.gov.uk/foreign-travel-advice/iran.atom"},
    {"n":"ğŸ›ï¸ UK FCDO Alerts",       "u":"https://www.gov.uk/foreign-travel-advice/iran/alerts.atom"},
    {"n":"ğŸ›ï¸ Embassy Evacuations",  "u":"https://news.google.com/rss/search?q=embassy+evacuation+Iran+Tehran+warning&hl=en-US&gl=US&ceid=US:en&num=10"},
    {"n":"ğŸ›ï¸ Iran Airspace",        "u":"https://news.google.com/rss/search?q=Iran+airspace+closure+flight+ban&hl=en-US&gl=US&ceid=US:en&num=10"},
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŒ  Ø¨ÛŒÙ†â€ŒØ§Ù„Ù…Ù„Ù„ÛŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INTL_FEEDS = [
    {"n":"ğŸŒ BBC Middle East",  "u":"https://feeds.bbci.co.uk/news/world/middle_east/rss.xml"},
    {"n":"ğŸŒ Al Jazeera",       "u":"https://www.aljazeera.com/xml/rss/all.xml"},
    {"n":"ğŸŒ Middle East Eye",  "u":"https://www.middleeasteye.net/rss"},
    {"n":"ğŸŒ Al-Monitor GNews", "u":"https://news.google.com/rss/search?q=site:al-monitor.com+Iran+Israel+war&hl=en-US&gl=US&ceid=US:en"},
    {"n":"âš ï¸ DEFCON Iran",      "u":"https://news.google.com/rss/search?q=DEFCON+nuclear+Iran+Israel+escalation&hl=en-US&gl=US&ceid=US:en"},
]

ALL_RSS_FEEDS = IRAN_FEEDS + ISRAEL_FEEDS + USA_FEEDS + EMBASSY_FEEDS + INTL_FEEDS
EMBASSY_SET = set(id(f) for f in EMBASSY_FEEDS)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“¢  Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… â€” Ø®Ø§ÙˆØ±Ù…ÛŒØ§Ù†Ù‡ØŒ Ø®Ù„ÛŒØ¬â€ŒÙØ§Ø±Ø³ØŒ OSINT Ù†Ø¸Ø§Ù…ÛŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_CHANNELS = [
    # OSINT Ù†Ø¸Ø§Ù…ÛŒ â€” Ø¨Ø±ØªØ±ÛŒÙ†
    ("ğŸ”´ Middle East Spectator", "Middle_East_Spectator"),
    ("ğŸ”´ Intel Slava Z",         "intelslava"),
    ("ğŸ”´ ELINT News",            "ELINTNews"),
    ("ğŸ”´ Megatron OSINT",        "Megatron_Ron"),
    ("ğŸ”´ Disclose TV",           "disclosetv"),
    ("ğŸ” Military Milk",         "militarymilk"),
    ("ğŸ” OSINTtechnical",        "Osinttechnical"),
    ("ğŸ” Iran OSINT",            "IranOSINT"),
    ("ğŸ” Aurora Intel",          "Aurora_Intel"),
    ("ğŸ” War Monitor",           "WarMonitor3"),
    # Ø§ÛŒØ±Ø§Ù†
    ("ğŸ‡®ğŸ‡· Iran Intl Persian",   "IranIntlPersian"),
    ("ğŸ‡®ğŸ‡· ØªØ³Ù†ÛŒÙ… ÙØ§Ø±Ø³ÛŒ",         "tasnimnewsfa"),
    ("ğŸ‡®ğŸ‡· Ù…Ù‡Ø± ÙØ§Ø±Ø³ÛŒ",            "mehrnews_fa"),
    ("ğŸ‡®ğŸ‡· Ø§ÛŒØ±Ù†Ø§ ÙØ§Ø±Ø³ÛŒ",          "irnafarsi"),
    ("ğŸ‡®ğŸ‡· Press TV",             "PressTVnews"),
    ("ğŸ‡®ğŸ‡· Radio Farda",          "radiofarda"),
    # Ø§Ø³Ø±Ø§ÛŒÛŒÙ„
    ("ğŸ‡®ğŸ‡± Kann News",            "kann_news"),
    ("ğŸ‡®ğŸ‡± Times of Israel",      "timesofisrael"),
    # Ø®Ù„ÛŒØ¬â€ŒÙØ§Ø±Ø³
    ("ğŸ‡¸ğŸ‡¦ Al Arabiya Breaking",  "AlArabiya_Brk"),
    ("ğŸ‡¶ğŸ‡¦ Al Jazeera EN",        "AlJazeeraEnglish"),
    ("ğŸ‡¦ğŸ‡ª Sky News Arabia",      "SkyNewsArabia"),
    ("ğŸ‡®ğŸ‡¶ Al Sumaria Iraq",      "alsumaria_tv"),
    # ÛŒÙ…Ù†
    ("ğŸ‡¾ğŸ‡² Masirah TV",           "AlMasirahNet"),
    ("ğŸ‡¾ğŸ‡² Saba News",            "sabaafp"),
    # Ù„Ø¨Ù†Ø§Ù†
    ("ğŸ‡±ğŸ‡§ Naharnet",             "Naharnet"),
    ("ğŸ‡±ğŸ‡§ LBCI News",            "LBCI_News"),
    # ØªØ±Ú©ÛŒÙ‡
    ("ğŸ‡¹ğŸ‡· Yeni Safak EN",        "YeniSafakEN"),
    ("ğŸ‡¹ğŸ‡· TRT World",            "TRTWorldnow"),
    # Ø¨ÛŒÙ†â€ŒØ§Ù„Ù…Ù„Ù„ÛŒ
    ("ğŸŒ Reuters Breaking",      "ReutersBreaking"),
    ("ğŸŒ AP News",               "APnews"),
    ("ğŸŒ BBC Breaking",          "BBCBreaking"),
    ("ğŸŒ AFP News",              "AFPnews"),
    ("ğŸŒ GeoConfirmed",          "GeoConfirmed"),
    ("ğŸŒ IntelCrab",             "IntelCrab"),
    ("ğŸŒ OSINTdefender",         "OSINTdefender"),
    ("ğŸŒ War Zone",              "TheWarZoneTW"),
    ("ğŸŒ OSINT Ukraine",         "osint_ukr"),
    ("ğŸŒ Warfare Analysis",      "WarfareAnalysis"),
    ("ğŸŒ Breaking Defense",      "BreakingDefenseNews"),
]

TG_UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0"
TG_HEADERS = {"User-Agent": TG_UA, "Accept": "text/html,application/xhtml+xml;q=0.9,*/*;q=0.8", "Accept-Language": "en-US,en;q=0.5"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğ•  Twitter / Nitter
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TWITTER_HANDLES = [
    # ğŸ‡®ğŸ‡· Ø§ÛŒØ±Ø§Ù† â€” Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± / ØªØ­Ù„ÛŒÙ„Ú¯Ø±
    ("ğŸ‡®ğŸ‡· IRNA EN",               "IRNA_English"),
    ("ğŸ‡®ğŸ‡· IranIntl EN",           "IranIntl_En"),
    ("ğŸ‡®ğŸ‡· Press TV",              "PressTV"),
    ("ğŸ‡®ğŸ‡· Farnaz Fassihi",        "farnazfassihi"),       # Ù†ÛŒÙˆÛŒÙˆØ±Ú© ØªØ§ÛŒÙ…Ø²
    ("ğŸ‡®ğŸ‡· Negar Mortazavi",       "NegarMortazavi"),
    ("ğŸ‡®ğŸ‡· Ali Vaez",              "AliVaez"),             # Ù…Ø¯ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡ Ø§ÛŒØ±Ø§Ù† / ICG
    ("ğŸ‡®ğŸ‡· Golnaz Esfandiari",     "GEsfandiari"),         # Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± Ø§Ø±Ø´Ø¯ RFE/RL
    ("ğŸ‡®ğŸ‡· Sina Toossi",           "SinaToossi"),          # ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù…Ø±Ú©Ø² Ø³ÛŒØ§Ø³Øª Ø¨ÛŒÙ†â€ŒØ§Ù„Ù…Ù„Ù„ÛŒ
    ("ğŸ‡®ğŸ‡· Holly Dagres",          "hdagres"),             # Ù¾Ú˜ÙˆÙ‡Ø´Ú¯Ø± Ø´ÙˆØ±Ø§ÛŒ Ø¢ØªÙ„Ø§Ù†ØªÛŒÚ©
    ("ğŸ‡®ğŸ‡· Saeed Ghasseminejad",   "SGhasseminejad"),      # Ù…Ø´Ø§ÙˆØ± Ø§Ø±Ø´Ø¯ FDD
    ("ğŸ‡®ğŸ‡· Kasra Aarabi",          "KasraAarabi"),         # Ù…Ø¯ÛŒØ± ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø³Ù¾Ø§Ù‡ / UANI
    # ğŸ‡ºğŸ‡¸ Ø¢Ù…Ø±ÛŒÚ©Ø§ â€” Ø¯ÙˆÙ„ØªÛŒ / Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± / ØªØ­Ù„ÛŒÙ„Ú¯Ø±
    ("ğŸ‡ºğŸ‡¸ CENTCOM",               "CENTCOM"),
    ("ğŸ‡ºğŸ‡¸ DoD",                   "DeptofDefense"),
    ("ğŸ‡ºğŸ‡¸ Marco Rubio",           "marcorubio"),
    ("ğŸ‡ºğŸ‡¸ Natasha Bertrand",      "NatashaBertrand"),     # CNN
    ("ğŸ‡ºğŸ‡¸ Barak Ravid",           "BarakRavid"),          # Axios
    ("ğŸ‡ºğŸ‡¸ Idrees Ali",            "idreesali114"),        # Reuters
    ("ğŸ‡ºğŸ‡¸ Lara Seligman",         "laraseligman"),        # Politico
    ("ğŸ‡ºğŸ‡¸ Jack Detsch",           "JackDetsch"),          # Foreign Policy
    ("ğŸ‡ºğŸ‡¸ Trita Parsi",           "tparsi"),              # Ø¨Ù†ÛŒØ§Ù†â€ŒÚ¯Ø°Ø§Ø± Ù…ÙˆØ³Ø³Ù‡ Ú©ÙˆØ¦ÛŒÙ†Ø³ÛŒ
    ("ğŸ‡ºğŸ‡¸ Barbara Slavin",        "barbaraslavin1"),      # Ù…Ø±Ú©Ø² Ø§Ø³ØªÛŒÙ…Ø³ÙˆÙ†
    ("ğŸ‡ºğŸ‡¸ Ian Bremmer",           "ianbremmer"),          # Ø±Ø¦ÛŒØ³ Ú¯Ø±ÙˆÙ‡ Ø§ÙˆØ±Ø§Ø³ÛŒØ§
    ("ğŸ‡ºğŸ‡¸ Jim Sciutto",           "jimsciutto"),          # ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø´Ø¯ Ø§Ù…Ù†ÛŒØª Ù…Ù„ÛŒ CNN
    ("ğŸ‡ºğŸ‡¸ Michael Knights",       "Mikeknightsiraq"),     # Ù…ÙˆØ³Ø³Ù‡ ÙˆØ§Ø´Ù†Ú¯ØªÙ†
    # ğŸ‡ªğŸ‡º Ø§Ø±ÙˆÙ¾Ø§ â€” Ø§Ù†Ø¯ÛŒØ´Ú©Ø¯Ù‡ / Ø®Ø¨Ø±Ù†Ú¯Ø§Ø±
    ("ğŸ‡ªğŸ‡º Ellie Geranmayeh",      "EllieGeranmayeh"),     # ECFR â€” Ø§Ø±Ø´Ø¯ØªØ±ÛŒÙ† Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø§ÛŒØ±Ø§Ù† Ø§Ø±ÙˆÙ¾Ø§
    ("ğŸ‡ªğŸ‡º Carl Bildt",            "carlbildt"),           # Ø±Ø¦ÛŒØ³ Ù…Ø´ØªØ±Ú© ECFR / Ù†Ø®Ø³Øªâ€ŒÙˆØ²ÛŒØ± Ø³Ø§Ø¨Ù‚ Ø³ÙˆØ¦Ø¯
    ("ğŸ‡ªğŸ‡º Julien Barnes-Dacey",   "jbarnesdacey"),        # Ù…Ø¯ÛŒØ± Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ÙˆØ±Ù…ÛŒØ§Ù†Ù‡ ECFR
    ("ğŸ‡ªğŸ‡º Neil Quilliam",         "NeilQuilliam1"),       # Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø®Ø§ÙˆØ±Ù…ÛŒØ§Ù†Ù‡ / Chatham House
    # ğŸ‡®ğŸ‡± Ø§Ø³Ø±Ø§ÛŒÛŒÙ„ â€” Ø±Ø³Ù…ÛŒ / Ø®Ø¨Ø±Ù†Ú¯Ø§Ø±
    ("ğŸ‡®ğŸ‡± IDF",                   "IDF"),
    ("ğŸ‡®ğŸ‡± Israeli PM",            "IsraeliPM"),
    ("ğŸ‡®ğŸ‡± Yossi Melman",          "yossi_melman"),        # Mossad / Ø§Ù…Ù†ÛŒØª
    ("ğŸ‡®ğŸ‡± Seth Frantzman",        "sfrantzman"),          # Jerusalem Post
    ("ğŸ‡®ğŸ‡± Amos Harel",            "AmosHarel"),           # Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± Ø§Ø±Ø´Ø¯ Ù†Ø¸Ø§Ù…ÛŒ Haaretz
    ("ğŸ‡®ğŸ‡± Yaakov Katz",           "yaakovkatz"),          # Ø³Ø±Ø¯Ø¨ÛŒØ± Ø³Ø§Ø¨Ù‚ JP / ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù†Ø¸Ø§Ù…ÛŒ
    ("ğŸ‡®ğŸ‡± Anshel Pfeffer",        "AnshelPfeffer"),       # Haaretz / The Economist
    ("ğŸ‡®ğŸ‡± Anna Ahronheim",        "AAhronheim"),          # Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± Ù†Ø¸Ø§Ù…ÛŒ
    ("ğŸ‡®ğŸ‡± Emanuel Fabian",        "manniefabian"),        # Times of Israel
    ("ğŸ‡®ğŸ‡± Tal Schneider",         "talschneider"),        # Times of Israel Ø¯ÛŒÙ¾Ù„Ù…Ø§Ø³ÛŒ
    # ğŸ” OSINT / Ù¾Ø§ÛŒØ´
    ("ğŸ” OSINTdefender",          "OSINTdefender"),
    ("ğŸ” IntelCrab",              "IntelCrab"),
    ("ğŸ” WarMonitor",             "WarMonitor3"),
    ("ğŸ” GeoConfirmed",           "GeoConfirmed"),
    ("ğŸ” AuroraIntel",            "AuroraIntel"),
    ("ğŸ” Faytuks News",           "Faytuks"),             # Ù¾ÙˆØ´Ø´ Ø³Ø±ÛŒØ¹ Ø§Ø®Ø¨Ø§Ø± Ù†Ø¸Ø§Ù…ÛŒ
    ("ğŸ” Clash Report",           "clashreport"),         # Ù¾ÙˆØ´Ø´ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø±Ú¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§
    ("ğŸ” Aric Toler",             "AricToler"),           # NYT / Ø¹Ø¶Ùˆ Ø³Ø§Ø¨Ù‚ Bellingcat
    ("âš ï¸ DEFCONLevel",            "DEFCONLevel"),
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğ•  Twitter/X â€” Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ø¯Ùˆ Ù…Ù†Ø¨Ø¹: RSSHub + Nitter
#
# Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Ù‚Ø¨Ù„ÛŒ: GitHub Actions IP ØªÙˆØ³Ø· Nitter instances block Ù…ÛŒâ€ŒØ´Ø¯
# Ø±Ø§Ù‡â€ŒØ­Ù„: RSSHub Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø¨Ø¹ Ø§ÙˆÙ„ + Nitter Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† fallback
#
# RSSHub: Ø³Ø±ÙˆÛŒØ³ RSS Ø¨Ø±Ø§ÛŒ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ â€” instance Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†
# Nitter: mirror ØªÙˆÛŒÛŒØªØ± â€” probe ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† instance Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# RSSHub public instances â€” Ø¨Ø±Ø§ÛŒ Twitter/X
RSSHUB_INSTANCES = [
    "https://rsshub.rss.now.sh",
    "https://rsshub.app",
    "https://rss.shab.fun",
    "https://rsshub.moeyy.xyz",
    "https://rsshub.feeded.xyz",
    "https://rsshub.atgaw.cc",
]

# Nitter instances â€” fallback
NITTER_FALLBACK = [
    "https://xcancel.com",
    "https://nitter.poast.org",
    "https://nitter.privacyredirect.com",
    "https://lightbrd.com",
    "https://nitter.tiekoetter.com",
    "https://nuku.trabun.org",
    "https://nitter.catsarch.com",
    "https://nitter.space",
]

NITTER_CACHE_FILE = "nitter_cache.json"
NITTER_CACHE_TTL  = 1800   # Û³Û° Ø¯Ù‚ÛŒÙ‚Ù‡

NITTER_HDR = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:124.0) Gecko/20100101 Firefox/124.0",
    "Accept": "application/rss+xml,application/xml,text/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Cache-Control": "no-cache",
}

TW_TIMEOUT = 8.0

_nitter_pool: list[str] = []
_rsshub_pool: list[str] = []
_NITTER_SEMA: asyncio.Semaphore | None = None

def _load_nitter_disk() -> tuple[list[str], float]:
    try:
        if Path(NITTER_CACHE_FILE).exists():
            d = json.load(open(NITTER_CACHE_FILE))
            return d.get("nitter", []), d.get("ts", 0.0)
    except: pass
    return [], 0.0

def _save_nitter_disk(nitter: list[str]):
    json.dump({"nitter": nitter, "ts": datetime.now(timezone.utc).timestamp()},
              open(NITTER_CACHE_FILE, "w"))

def _is_rss_body(body: str, ct: str) -> bool:
    return ("xml" in ct) or ("<rss" in body[:500]) or body.lstrip()[:6].startswith("<?xml")

async def _fetch_rss_url(client: httpx.AsyncClient, url: str,
                          timeout: float = TW_TIMEOUT) -> list:
    """
    GET ÛŒÚ© URL Ùˆ parse RSS â€” Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ list Ø§Ø² entries ÛŒØ§ []
    """
    try:
        r = await client.get(url, headers=NITTER_HDR,
                             timeout=httpx.Timeout(connect=4.0, read=timeout,
                                                   write=4.0, pool=4.0))
        if r.status_code not in (200,):
            return []
        if not _is_rss_body(r.text, r.headers.get("content-type", "")):
            return []
        entries = feedparser.parse(r.text).entries
        return [e for e in entries if len(e.get("title", "").strip()) > 5]
    except Exception:
        return []

async def _probe_nitter(client: httpx.AsyncClient, inst: str) -> tuple[str, float] | None:
    """Probe ÛŒÙ‡ Nitter instance â€” Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ (url, ms) ÛŒØ§ None"""
    t0 = asyncio.get_running_loop().time()
    entries = await _fetch_rss_url(client, f"{inst}/CENTCOM/rss", timeout=5.0)
    if entries:
        return inst, (asyncio.get_running_loop().time() - t0) * 1000
    return None

async def _probe_rsshub(client: httpx.AsyncClient, inst: str) -> tuple[str, float] | None:
    """Probe ÛŒÙ‡ RSSHub instance â€” test Ø¨Ø§ CENTCOM"""
    t0 = asyncio.get_running_loop().time()
    entries = await _fetch_rss_url(client, f"{inst}/twitter/user/CENTCOM", timeout=6.0)
    if entries:
        return inst, (asyncio.get_running_loop().time() - t0) * 1000
    return None

async def build_twitter_pools(client: httpx.AsyncClient):
    """
    Ø³Ø§Ø®Øª pool Ø§Ø² Nitter Ùˆ RSSHub â€” Ù…ÙˆØ§Ø²ÛŒ
    Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Ø¨Ø±Ø§ÛŒ NITTER_CACHE_TTL Ø«Ø§Ù†ÛŒÙ‡
    """
    global _nitter_pool, _rsshub_pool

    if _nitter_pool or _rsshub_pool:
        return   # Ù‚Ø¨Ù„Ø§Ù‹ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡

    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´
    cached, ts = _load_nitter_disk()
    age = datetime.now(timezone.utc).timestamp() - ts
    if cached and age < NITTER_CACHE_TTL:
        _nitter_pool = cached
        log.info(f"ğ• Nitter Ø§Ø² cache: {len(_nitter_pool)} inst")
        return

    # probe Ù…ÙˆØ§Ø²ÛŒ
    log.info(f"ğ• Probing {len(NITTER_FALLBACK)} Nitter + {len(RSSHUB_INSTANCES)} RSSHub...")

    sema = asyncio.Semaphore(10)

    async def safe_probe(coro):
        async with sema:
            try: return await coro
            except: return None

    nitter_tasks  = [safe_probe(_probe_nitter(client, u)) for u in NITTER_FALLBACK]
    rsshub_tasks  = [safe_probe(_probe_rsshub(client, u)) for u in RSSHUB_INSTANCES]
    all_results   = await asyncio.gather(*nitter_tasks, *rsshub_tasks)

    n = len(NITTER_FALLBACK)
    nitter_ok  = sorted([r for r in all_results[:n]  if r], key=lambda x: x[1])
    rsshub_ok  = sorted([r for r in all_results[n:]  if r], key=lambda x: x[1])

    _nitter_pool = [u for u, _ in nitter_ok]  or NITTER_FALLBACK[:3]
    _rsshub_pool = [u for u, _ in rsshub_ok]

    log.info(f"ğ• Nitter: {len(_nitter_pool)} ÙØ¹Ø§Ù„ | RSSHub: {len(_rsshub_pool)} ÙØ¹Ø§Ù„")
    if nitter_ok:
        log.info(f"  Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† Nitter: {nitter_ok[0][0].split('//')[-1]} ({nitter_ok[0][1]:.0f}ms)")
    if rsshub_ok:
        log.info(f"  Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† RSSHub: {rsshub_ok[0][0].split('//')[-1]} ({rsshub_ok[0][1]:.0f}ms)")

    _save_nitter_disk(_nitter_pool)

async def fetch_twitter(client: httpx.AsyncClient, label: str, handle: str) -> list:
    """
    Ø¯Ø±ÛŒØ§ÙØª ØªÙˆÛŒÛŒØªâ€ŒÙ‡Ø§ÛŒ ÛŒÚ© handle â€” Ø³Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø§ÙˆÙ„ÙˆÛŒØª:
    1. RSSHub (Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† instance Ú©Ø§Ø±â€ŒÚ©Ø±Ø¯Ù‡ Ø§Ø² probe)
    2. Nitter (Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† instance Ú©Ø§Ø±â€ŒÚ©Ø±Ø¯Ù‡ Ø§Ø² probe)
    3. Fallback Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ xcancel.com

    Ø³Ù…Ø§ÙÙˆØ± Ú©Ù„ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨ÛŒØ´ Ø§Ø² Û±Û° request Ù‡Ù…Ø²Ù…Ø§Ù†
    """
    sema = _NITTER_SEMA if _NITTER_SEMA is not None else asyncio.Semaphore(10)

    async with sema:
        # â”€â”€ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Û±: RSSHub
        for inst in (_rsshub_pool or RSSHUB_INSTANCES[:2]):
            entries = await _fetch_rss_url(client, f"{inst}/twitter/user/{handle}")
            if entries:
                log.debug(f"ğ• âœ… {handle} Ø§Ø² RSSHub/{inst.split('//')[-1]}")
                return [(e, f"ğ• {label}", "tw", False) for e in entries]

        # â”€â”€ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Û²: Nitter
        pool = _nitter_pool or NITTER_FALLBACK
        start = abs(hash(handle)) % len(pool)
        for inst in (pool * 2)[start: start + min(3, len(pool))]:
            entries = await _fetch_rss_url(client, f"{inst}/{handle}/rss")
            if entries:
                log.debug(f"ğ• âœ… {handle} Ø§Ø² Nitter/{inst.split('//')[-1]}")
                return [(e, f"ğ• {label}", "tw", False) for e in entries]

        # â”€â”€ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Û³: xcancel.com Ù…Ø³ØªÙ‚ÛŒÙ…
        entries = await _fetch_rss_url(client, f"https://xcancel.com/{handle}/rss")
        if entries:
            log.debug(f"ğ• âœ… {handle} Ø§Ø² xcancel.com (fallback)")
            return [(e, f"ğ• {label}", "tw", False) for e in entries]

    log.debug(f"ğ• âœ— {handle}: Ù‡Ù…Ù‡ Û³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ fail")
    return []






# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœˆï¸  ADS-B â€” Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§ÛŒ Ù†Ø¸Ø§Ù…ÛŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ADSB_API = "https://api.adsb.one/v2"
ADSB_REGIONS = [
    ("Ø§ÛŒØ±Ø§Ù†",         32.4, 53.7, 250),
    ("Ø®Ù„ÛŒØ¬â€ŒÙØ§Ø±Ø³",    26.5, 52.0, 250),
    ("Ø§Ø³Ø±Ø§ÛŒÛŒÙ„/Ù„Ø¨Ù†Ø§Ù†",32.1, 35.2, 200),
    ("Ø¹Ø±Ø§Ù‚",          33.3, 44.4, 250),
    ("Ø¯Ø±ÛŒØ§ÛŒ Ø³Ø±Ø®",    15.0, 43.0, 250),
]
MIL_CALLSIGN_PREFIXES = {
    "RCH":"C-17 (Ø­Ù…Ù„ Ù†Ø¸Ø§Ù…ÛŒ)","LAGR":"RQ-4 Global Hawk","REDEYE":"KC-135 Ø³ÙˆØ®Øªâ€ŒØ±Ø³Ø§Ù†",
    "DUKE":"AC-130 Gunship","ROCKY":"B-52","VADER":"F-22","GRIM":"B-1B",
    "RACER":"B-2 Spirit","JAKE":"F-15E","REACH":"C-17","STEEL":"KC-46",
    "OASIS":"E-3 AWACS","COBRA":"RC-135 Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ","SPAR":"Ù‡ÙˆØ§Ù¾ÛŒÙ…Ø§ÛŒ VIP",
    "SAM":"Air Force One","IRON":"F-16","ASLAN":"F-35",
}
SPECIAL_AC_TYPES = {"B52":"Ø¨Ù…Ø¨â€ŒØ§ÙÚ©Ù† B-52","B1":"Ø¨Ù…Ø¨â€ŒØ§ÙÚ©Ù† B-1","B2":"Ø¨Ù…Ø¨â€ŒØ§ÙÚ©Ù† B-2 Ù…Ø®ÙÛŒ",
                    "F35":"Ø¬Ù†Ú¯Ù†Ø¯Ù‡ F-35","F22":"Ø¬Ù†Ú¯Ù†Ø¯Ù‡ F-22","KC135":"Ø³ÙˆØ®Øªâ€ŒØ±Ø³Ø§Ù† KC-135",
                    "KC46":"Ø³ÙˆØ®Øªâ€ŒØ±Ø³Ø§Ù† KC-46","E3":"AWACS","RC135":"Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ RC-135",
                    "RQ4":"Ù¾Ù‡Ù¾Ø§Ø¯ Global Hawk","MQ9":"Ù¾Ù‡Ù¾Ø§Ø¯ Reaper","C17":"C-17",
                    "P8":"P-8 Poseidon","C5":"C-5 Galaxy"}

def load_flight_alerts() -> dict:
    try:
        if Path(FLIGHT_ALERT_FILE).exists():
            d = json.load(open(FLIGHT_ALERT_FILE))
            cutoff = datetime.now(timezone.utc).timestamp() - 3600
            return {k:v for k,v in d.items() if v.get("t",0) > cutoff}
    except: pass
    return {}

def save_flight_alerts(d): json.dump(d, open(FLIGHT_ALERT_FILE,"w"))

async def fetch_military_flights(client: httpx.AsyncClient) -> list[dict]:
    known  = load_flight_alerts()
    alerts = []
    hdrs   = {"User-Agent":"WarBot/13"}

    for region, lat, lon, radius in ADSB_REGIONS:
        url = f"{ADSB_API}/point/{lat}/{lon}/{radius}"
        try:
            r = await client.get(url, headers=hdrs, timeout=httpx.Timeout(12.0))
            if r.status_code != 200: continue
            aircraft = r.json().get("ac", [])

            for ac in aircraft:
                db_flags = ac.get("dbFlags", 0)
                is_mil   = bool(db_flags & 1)
                typ      = (ac.get("t") or "").upper()
                call     = (ac.get("flight") or "").strip().upper()
                icao     = ac.get("hex","")
                if not icao: continue

                interesting_t = any(s in typ for s in SPECIAL_AC_TYPES)
                interesting_c = any(call.startswith(p) for p in MIL_CALLSIGN_PREFIXES)

                if not (is_mil or interesting_t or interesting_c):
                    continue

                uid = f"{icao}_{int(datetime.now(timezone.utc).timestamp()//1800)}"
                if uid in known: continue

                alt  = ac.get("alt_baro","?")
                spd  = int(ac.get("gs",0))
                lat2 = ac.get("lat",0)
                lon2 = ac.get("lon",0)
                hdg  = int(ac.get("track") or ac.get("true_heading") or 0)
                emrg = ac.get("emergency","none")
                sq   = ac.get("squawk","")
                reg  = ac.get("r","")

                type_desc = SPECIAL_AC_TYPES.get(typ, MIL_CALLSIGN_PREFIXES.get(call[:4],"Ù‡ÙˆØ§Ù¾ÛŒÙ…Ø§ÛŒ Ù†Ø¸Ø§Ù…ÛŒ"))
                emrg_txt  = " ğŸš¨ Ø§ÙˆØ±Ú˜Ø§Ù†Ø³!" if emrg not in ("none","") else ""

                msg = (
                    f"âœˆï¸ <b>ØªØ­Ø±Ú© Ù†Ø¸Ø§Ù…ÛŒ â€” {region}</b>{emrg_txt}\n"
                    f"â–¸ Ù†ÙˆØ¹: <b>{type_desc}</b>\n"
                    f"â–¸ Ú©Ø§Ù„â€ŒØ³Ø§ÛŒÙ†: {call or 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…'}"+(f"  |  Ø±Ø¬ÛŒØ³ØªØ±ÛŒ: {reg}" if reg else "")+"\n"
                    f"â–¸ Ø§Ø±ØªÙØ§Ø¹: {alt if isinstance(alt,str) else f'{int(alt):,} ft'}"
                    f"  |  Ø³Ø±Ø¹Øª: {spd} kt"+(f"  |  Ù‡Ø¯ÛŒÙ†Ú¯: {hdg}Â°" if hdg else "")+"\n"
                    f"â–¸ Ù…ÙˆÙ‚Ø¹ÛŒØª: {lat2:.2f}Â°N, {lon2:.2f}Â°E\n"
                    +(f"â–¸ Ø§Ø³Ú©ÙˆØ§Ú©: {sq}" if sq and sq not in ("0000","7777","2000") else "")
                    +f"\nğŸ”— <a href='https://globe.adsbexchange.com/?icao={icao}'>ADS-B Exchange</a>"
                )

                known[uid] = {"t": datetime.now(timezone.utc).timestamp()}
                alerts.append(msg)
                if len(alerts) >= 4: break

        except Exception as e: log.debug(f"ADS-B {region}: {e}")

    save_flight_alerts(known)
    return alerts

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¨  Ú©Ø§Ø±Øª Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ PIL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ACCENT_MAP = {
    "ğŸ‡®ğŸ‡·":(0,100,170),"ğŸ‡®ğŸ‡±":(0,90,200),"ğŸ‡ºğŸ‡¸":(178,34,52),
    "ğŸ›ï¸":(100,70,180),"âœˆï¸":(10,130,110),"ğŸ”´":(210,40,40),
    "âš ï¸":(210,150,0), "ğŸŒ":(40,110,170),"ğŸ”":(70,90,100),
    "ğ•": (15,15,15),  "ğŸ“¢":(50,140,200),"ğŸ“¡":(60,120,60),
}
BG_DARK  = (14,16,22)
BG_BAR   = (22,26,34)
FG_WHITE = (235,237,242)
FG_GREY  = (120,132,148)

def _get_accent(src:str, urgent:bool) -> tuple:
    if urgent: return (210,40,40)
    for k,v in ACCENT_MAP.items():
        if src.startswith(k) or k in src: return v
    return (80,110,140)

def _wrap_text(text:str, chars:int) -> list[str]:
    words, lines, cur = text.split(), [], ""
    for w in words:
        if len(cur)+len(w)+1 <= chars: cur=(cur+" "+w).strip()
        else:
            if cur: lines.append(cur)
            cur=w
    if cur: lines.append(cur)
    return lines

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“°  Article Content Fetcher â€” Ø¨Ø±Ø§ÛŒ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ù…Ù‡Ù… (Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† screenshot)
#
# Ø¨Ù‡ Ø¬Ø§ÛŒ browser screenshot:
# - httpx GET ØµÙØ­Ù‡ â†’ BeautifulSoup â†’ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ù…Ù‚Ø§Ù„Ù‡
# - Ø³Ø§Ø®Øª PIL Ú©Ø§Ø±Øª ØºÙ†ÛŒ Ø¨Ø§ Ù…ØªÙ† Ú©Ø§Ù…Ù„
# Ø§ÛŒÙ† Ø±ÙˆØ´: Ø³Ø±ÛŒØ¹ (< 2s)ØŒ Ø¨ÛŒâ€ŒÙ†ÛŒØ§Ø² Ø¨Ù‡ browserØŒ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ GitHub Actions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_ARTICLE_SELECTORS = [
    "article", "[class*='article-body']", "[class*='post-body']",
    "[class*='story-body']", "[class*='content-body']",
    ".entry-content", ".post-content", ".article-text",
    "[itemprop='articleBody']", ".body-content", "main",
]
_SKIP_TAGS = {"script","style","nav","header","footer","aside","form","button","iframe"}

async def fetch_article_text(client: httpx.AsyncClient, url: str) -> str:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ù…Ù‚Ø§Ù„Ù‡ Ø§Ø² URL â€” Ø¨Ø¯ÙˆÙ† browser
    Ø®Ø±ÙˆØ¬ÛŒ: Ù…ØªÙ† Ú©Ø§Ù…Ù„ (Ø­Ø¯Ø§Ú©Ø«Ø± Û±Û²Û°Û° Ú©Ø§Ø±Ø§Ú©ØªØ±)
    """
    if not url or url.startswith("https://t.me"):
        return ""
    try:
        hdrs = dict(COMMON_UA)
        hdrs["Accept"] = "text/html,application/xhtml+xml;q=0.9,*/*;q=0.8"
        r = await client.get(url, timeout=httpx.Timeout(8.0), headers=hdrs,
                             follow_redirects=True)
        if r.status_code != 200:
            return ""
        soup = BeautifulSoup(r.text, "html.parser")

        # Ø­Ø°Ù ØªÚ¯â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ù…ÙÛŒØ¯
        for tag in soup.find_all(_SKIP_TAGS):
            tag.decompose()

        # Ø§Ù…ØªØ­Ø§Ù† selector Ù‡Ø§ÛŒ Ù…ØªØ¯Ø§ÙˆÙ„
        for sel in _ARTICLE_SELECTORS:
            el = soup.select_one(sel)
            if el:
                txt = el.get_text(" ", strip=True)
                if len(txt) > 150:
                    return txt[:1200]

        # fallback: Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† <p> block
        paras = [p.get_text(" ", strip=True) for p in soup.find_all("p") if len(p.get_text()) > 60]
        return " ".join(paras)[:1200] if paras else ""

    except Exception:
        return ""


def make_rich_card(headline: str, fa_text: str, article_body: str,
                   src: str, dt_str: str, urgent: bool,
                   sentiment_icons: list) -> io.BytesIO | None:
    """
    PIL Ú©Ø§Ø±Øª ØºÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ù…Ù‡Ù… (importance â‰¥ RICH_CARD_THRESHOLD):
    - Ù‡Ø¯Ø± Ø±Ù†Ú¯ÛŒ
    - Ø¹Ù†ÙˆØ§Ù† + Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ù…Ù‚Ø§Ù„Ù‡ (wrapping)
    - Ù†ÙˆØ§Ø± sentiment Ø¯Ø± Ù¾Ø§ÛŒÛŒÙ†
    Ø§Ø¨Ø¹Ø§Ø¯: 960 Ã— Ù…ØªØºÛŒØ± (Ø­Ø¯Ø§Ù‚Ù„ 400px)
    """
    if not PIL_OK: return None
    try:
        W = 960
        acc = _get_accent(src, urgent)
        try:
            F_src  = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 13)
            F_head = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 20)
            F_body = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 16)
            F_em   = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 20)
        except:
            F_src = F_head = F_body = F_em = ImageFont.load_default()

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø±ØªÙØ§Ø¹ Ù¾ÙˆÛŒØ§
        display = fa_text if (fa_text and fa_text != headline and len(fa_text) > 5) else headline
        head_lines = _wrap_text(display, 52)[:3]
        body_text  = article_body[:800] if article_body else ""
        body_lines = _wrap_text(body_text, 60)[:10] if body_text else []

        H = 5 + 53 + 3 + 12 + len(head_lines)*30 + 10 + len(body_lines)*24 + 10 + 56
        H = max(H, 320)

        img = Image.new("RGB", (W, H), BG_DARK)
        drw = ImageDraw.Draw(img)

        # Ù†ÙˆØ§Ø± Ø¨Ø§Ù„Ø§
        drw.rectangle([(0,0),(W,5)], fill=acc)
        drw.rectangle([(0,5),(W,58)], fill=BG_BAR)
        drw.rectangle([(0,58),(W,61)], fill=acc)
        drw.text((18,18), src[:55], font=F_src, fill=acc)
        drw.text((W-175,18), dt_str[:25], font=F_src, fill=FG_GREY)

        y = 72
        # Ø¹Ù†ÙˆØ§Ù† (RTL)
        for line in head_lines:
            drw.text((W-18, y), line, font=F_head, fill=FG_WHITE, anchor="ra")
            y += 30
        y += 8

        # Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡
        drw.line([(18, y),(W-18, y)], fill=(50,55,65), width=1)
        y += 10

        # Ù…ØªÙ† Ù…Ù‚Ø§Ù„Ù‡
        for line in body_lines:
            drw.text((W-18, y), line, font=F_body, fill=(195,200,210), anchor="ra")
            y += 24
        y += 8

        # Ù†ÙˆØ§Ø± sentiment
        drw.rectangle([(0, H-56),(W, H)], fill=BG_BAR)
        drw.rectangle([(0, H-58),(W, H-56)], fill=acc)
        ICON_BG = {
            "ğŸ’€":(140,20,20),"ğŸ”´":(180,30,30),"ğŸ’¥":(190,80,10),
            "âœˆï¸":(20,90,160),"ğŸš€":(100,20,160),"â˜¢ï¸":(0,130,50),
            "ğŸš¢":(10,80,140),"ğŸ•µï¸":(60,55,70),"ğŸ›¡ï¸":(20,110,80),
            "ğŸ”¥":(180,60,0),"ğŸ’°":(130,110,0),"âš ï¸":(160,110,0),
            "ğŸ¤":(20,120,100),"ğŸ“œ":(60,80,100),"ğŸ“°":(45,58,72),
        }
        x_pos = 16
        for ico in (sentiment_icons or ["ğŸ“°"])[:4]:
            bg = ICON_BG.get(ico, (50,65,75))
            drw.rounded_rectangle([(x_pos-2,H-52),(x_pos+38,H-6)], radius=7, fill=bg)
            drw.text((x_pos+2,H-50), ico, font=F_em, fill=(255,255,255))
            x_pos += 50

        # Ù†Ø´Ø§Ù†Ú¯Ø± ÙÙˆØ±ÛŒØª
        if urgent:
            drw.rectangle([(0,61),(5,H-58)], fill=acc)

        buf = io.BytesIO()
        img.save(buf, "JPEG", quality=85)
        buf.seek(0)
        return buf
    except Exception as e:
        log.debug(f"rich_card: {e}")
        return None

def make_news_card(headline:str, fa_text:str, src:str, dt_str:str,
                   link:str="", urgent:bool=False,
                   sentiment_icons:list|None=None) -> io.BytesIO | None:
    """PIL Ú©Ø§Ø±Øª Ø®Ø¨Ø±ÛŒ â€” Ù‡Ø¯Ø± Ø±Ù†Ú¯ÛŒ + Ù…ØªÙ† + Ù†ÙˆØ§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¯Ø± Ù¾Ø§ÛŒÛŒÙ†"""
    if not PIL_OK: return None
    try:
        W, H = 960, 310
        acc = _get_accent(src, urgent)
        img = Image.new("RGB", (W,H), BG_DARK)
        drw = ImageDraw.Draw(img)

        # Ù†ÙˆØ§Ø± Ø±Ù†Ú¯ÛŒ Ø¨Ø§Ù„Ø§
        drw.rectangle([(0,0),(W,5)], fill=acc)
        # Ù‡Ø¯Ø±
        drw.rectangle([(0,5),(W,58)], fill=BG_BAR)
        # Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ Ø§Ú©Ø³Ù†Øª
        drw.rectangle([(0,58),(W,61)], fill=acc)

        try:
            F_sm = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",14)
            F_H  = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",21)
            F_em = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",20)
        except:
            F_sm=F_H=F_em=ImageFont.load_default()

        # Ù…Ù†Ø¨Ø¹ Ø¯Ø± Ù‡Ø¯Ø±
        drw.text((18,18), src[:50], font=F_sm, fill=acc)
        drw.text((W-170,18), dt_str[:25], font=F_sm, fill=FG_GREY)

        # Ù…ØªÙ† Ø§ØµÙ„ÛŒ (Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
        y = 72
        body = fa_text if (fa_text and fa_text!=headline and len(fa_text)>5) else headline
        for line in _wrap_text(body, 50)[:3]:
            drw.text((W-18, y), line, font=F_H, fill=FG_WHITE, anchor="ra")
            y += 34

        # â”€â”€ Ù†ÙˆØ§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ù¾Ø§ÛŒÛŒÙ† Ú©Ø§Ø±Øª)
        drw.rectangle([(0, H-56),(W, H)], fill=BG_BAR)
        drw.rectangle([(0, H-58),(W, H-56)], fill=acc)   # Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡

        ICON_BG: dict[str,tuple] = {
            "ğŸ’€":(140,20,20),  "ğŸ”´":(180,30,30),  "ğŸ’¥":(190,80,10),
            "âœˆï¸":(20,90,160),  "ğŸš€":(100,20,160), "â˜¢ï¸":(0,130,50),
            "ğŸš¢":(10,80,140),  "ğŸ•µï¸":(60,55,70),   "ğŸ›¡ï¸":(20,110,80),
            "ğŸ”¥":(180,60,0),   "ğŸ’°":(130,110,0),  "âš ï¸":(160,110,0),
            "ğŸ¤":(20,120,100), "ğŸ“œ":(60,80,100),  "ğŸ“°":(45,58,72),
        }
        icons = sentiment_icons or ["ğŸ“°"]
        x_pos = 16
        for ico in icons[:4]:
            bg = ICON_BG.get(ico, (50,65,75))
            drw.rounded_rectangle(
                [(x_pos-2, H-52),(x_pos+38, H-6)],
                radius=7, fill=bg)
            drw.text((x_pos+2, H-50), ico, font=F_em, fill=(255,255,255))
            x_pos += 50

        # Ù†Ø´Ø§Ù†Ú¯Ø± ÙÙˆØ±ÛŒØª (Ù†ÙˆØ§Ø± Ú†Ù¾)
        if urgent:
            drw.rectangle([(0,61),(5,H-58)], fill=acc)

        buf = io.BytesIO()
        img.save(buf,"JPEG",quality=88)
        buf.seek(0)
        return buf
    except Exception as e:
        log.debug(f"PIL card: {e}")
        return None



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¯  ÙÛŒÙ„ØªØ± Ø¬Ù†Ú¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IRAN_KEYWORDS = [
    "iran","irgc","khamenei","tehran","iranian","revolutionary guard",
    "pasadaran","quds force","sepah","Ù¾Ø§Ø³Ø¯Ø§Ø±Ø§Ù†","Ø³Ù¾Ø§Ù‡","Ø§ÛŒØ±Ø§Ù†","Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒ",
    "hezbollah","hamas","houthi","ansarallah","Ø­Ø²Ø¨â€ŒØ§Ù„Ù„Ù‡","Ø­Ù…Ø§Ø³","Ø­ÙˆØ«ÛŒ",
    "pezeshkian","araghchi","zarif","Ù‚Ø§Ù„ÛŒØ¨Ø§Ù","Ø¢Ø±Ø§Ù‚Ú†ÛŒ","Ø§ÛŒØ±Ø§Ù†ÛŒ",
]
OPPONENT_KEYWORDS = [
    "israel","idf","mossad","netanyahu","tel aviv","israeli","Ø§Ø³Ø±Ø§ÛŒÛŒÙ„","Ù†ØªØ§Ù†ÛŒØ§Ù‡Ùˆ",
    "united states","us forces","pentagon","centcom","american","Ø¢Ù…Ø±ÛŒÚ©Ø§","ÙˆØ§Ø´Ù†Ú¯ØªÙ†",
    "trump","rubio","us military","us navy","us air force",
    "white house","state department","Ú©Ø§Ø® Ø³ÙÛŒØ¯","Ø¢Ù…Ø±ÛŒÚ©Ø§ÛŒÛŒ",
]
ACTION_KEYWORDS = [
    "attack","strike","airstrike","bomb","missile","rocket","drone","war",
    "conflict","military","kill","assassin","explosion","blast","threat",
    "escalat","retaliat","nuclear","weapon","sanction","intercept",
    "shot down","destroy","invade","operation","deploy","offensive",
    "Ø­Ù…Ù„Ù‡","Ù…ÙˆØ´Ú©","Ø¨Ù…Ø¨","Ù¾Ù‡Ù¾Ø§Ø¯","Ø§Ù†ÙØ¬Ø§Ø±","Ø¬Ù†Ú¯","Ø¹Ù…Ù„ÛŒØ§Øª","ØªÙ‡Ø¯ÛŒØ¯",
    "Ú©Ø´ØªÙ‡","Ø¶Ø±Ø¨Ù‡","Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ","ØªØ­Ø±ÛŒÙ…","ØªÙ„Ø§ÙÛŒ","Ø³Ø±Ù†Ú¯ÙˆÙ†","Ø§Ø³ØªÙ‚Ø±Ø§Ø±",
]
EMBASSY_OVERRIDE = [
    "travel advisory","security alert","leave iran","evacuate","do not travel",
    "airspace clos","flight suspend","flight ban","Ù‡Ø´Ø¯Ø§Ø± Ø³ÙØ§Ø±Øª","ØªØ±Ú© Ø§ÛŒØ±Ø§Ù†",
]
HARD_EXCLUDE = [
    "sport","football","soccer","olympic","basketball","tennis","wrestling",
    "weather","earthquake","flood","drought","volcano","quake",
    "covid","corona","vaccine","pharmacy","hospital alone",
    "music","concert","cinema","film","actor","actress","fashion","cooking",
    "Ú©Ø´ØªÛŒ","ÙÙˆØªØ¨Ø§Ù„","ÙˆØ±Ø²Ø´","Ù…ÙˆØ³ÛŒÙ‚ÛŒ","Ø³ÛŒÙ†Ù…Ø§","ÙˆØ§Ú©Ø³Ù†","Ø²Ù„Ø²Ù„Ù‡","Ø¢Ø¨â€ŒÙˆÙ‡ÙˆØ§",
]

def is_war_relevant(text:str, is_embassy=False, is_tg=False, is_tw=False) -> bool:
    txt = text.lower()
    if is_embassy and any(k in txt for k in EMBASSY_OVERRIDE): return True
    if any(k in txt for k in HARD_EXCLUDE): return False
    hi = any(k in txt for k in IRAN_KEYWORDS)
    ho = any(k in txt for k in OPPONENT_KEYWORDS)
    ha = any(k in txt for k in ACTION_KEYWORDS)
    if is_tg or is_tw: return (hi or ho) and ha
    return hi and ho and ha

def is_fresh(entry: dict, cutoff: datetime) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø²Ú¯ÛŒ Ø¢ÛŒØªÙ… Ù†Ø³Ø¨Øª Ø¨Ù‡ cutoff Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯"""
    try:
        t = entry.get("published_parsed") or entry.get("updated_parsed")
        if t:
            return datetime(*t[:6], tzinfo=timezone.utc) >= cutoff
        tg_dt = entry.get("_tg_dt")
        if tg_dt:
            return tg_dt >= cutoff
        # Ø¨Ø¯ÙˆÙ† ØªØ§Ø±ÛŒØ® â†’ Ø¨Ø±Ø±Ø³ÛŒ URL hash Ú©Ø§ÙÛŒÙ‡ (seen.json ØªÚ©Ø±Ø§Ø± Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡)
        return True
    except:
        return True



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§¹  Dedup â€” Ø³Ù‡â€ŒÙ„Ø§ÛŒÙ‡â€ŒØ§ÛŒ
#
#  Ù„Ø§ÛŒÙ‡ Û±: URL hash (seen.json)      â€” O(1) â€” ØªÚ©Ø±Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„
#  Ù„Ø§ÛŒÙ‡ Û²: Entity Triple matching    â€” O(n) â€” ØªÚ©Ø±Ø§Ø±ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ (WHO+ACTION+TARGET)
#  Ù„Ø§ÛŒÙ‡ Û³: Stemmed Jaccard fallback  â€” O(n) â€” ÙˆÙ‚ØªÛŒ triple Ú©ÙˆÚ†ÛŒÚ©Ù‡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ù†Ú¯Ø§Ø´Øª entity â†’ canonical code  (2 Ø­Ø±ÙÛŒ = actorØŒ 3+ Ø­Ø±ÙÛŒ = event-type)
WHO_MAP = {
    # Ø§ÛŒØ±Ø§Ù† Ùˆ Ù†ÛŒØ±ÙˆÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø¨ØªÛŒ
    "iran":"IR","iranian":"IR","irgc":"IR","sepah":"IR","khamenei":"IR",
    "pasadaran":"IR","revolutionary guard":"IR","quds force":"IR",
    "Ø§ÛŒØ±Ø§Ù†":"IR","Ø§ÛŒØ±Ø§Ù†ÛŒ":"IR","Ø³Ù¾Ø§Ù‡":"IR","Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒ":"IR","Ù¾Ø§Ø³Ø¯Ø§Ø±Ø§Ù†":"IR",
    "hezbollah":"HZ","Ø­Ø²Ø¨â€ŒØ§Ù„Ù„Ù‡":"HZ","Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡":"HZ","Ù†ØµØ±Ø§Ù„Ù„Ù‡":"HZ",
    "hamas":"HA","Ø­Ù…Ø§Ø³":"HA","sinwar":"HA",
    "houthi":"HT","Ø­ÙˆØ«ÛŒ":"HT","ansarallah":"HT","Ø§Ù†ØµØ§Ø±Ø§Ù„Ù„Ù‡":"HT",
    "pij":"PI","Ø¬Ù‡Ø§Ø¯ Ø§Ø³Ù„Ø§Ù…ÛŒ":"PI",
    # Ø§Ø³Ø±Ø§ÛŒÛŒÙ„
    "israel":"IL","idf":"IL","israeli":"IL","mossad":"IL","netanyahu":"IL",
    "tsahal":"IL","shin bet":"IL","aman":"IL","halevi":"IL",
    "Ø§Ø³Ø±Ø§ÛŒÛŒÙ„":"IL","Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„":"IL","Ù†ØªØ§Ù†ÛŒØ§Ù‡Ùˆ":"IL","Ù…ÙˆØ³Ø§Ø¯":"IL","Ø§Ø±ØªØ´ Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„":"IL",
    # Ø¢Ù…Ø±ÛŒÚ©Ø§
    "united states":"US","us army":"US","us navy":"US","us air force":"US",
    "us marine":"US","us forces":"US",
    "usa":"US","american":"US","america":"US","centcom":"US","pentagon":"US",
    "trump":"US","rubio":"US","austin":"US","milley":"US",
    "Ø¢Ù…Ø±ÛŒÚ©Ø§":"US","Ø¢Ù…Ø±ÛŒÚ©Ø§ÛŒÛŒ":"US","ØªØ±Ø§Ù…Ù¾":"US","Ø³Ù†ØªÚ©Ø§Ù…":"US","Ù¾Ù†ØªØ§Ú¯ÙˆÙ†":"US",
    # Ø¯ÛŒÚ¯Ø± Ø¨Ø§Ø²ÛŒÚ¯Ø±Ø§Ù† Ù…Ø±ØªØ¨Ø·
    "russia":"RU","russian":"RU","putin":"RU","Ø±ÙˆØ³ÛŒÙ‡":"RU","Ù¾ÙˆØªÛŒÙ†":"RU",
    "saudi":"SA","riyadh":"SA","Ø¹Ø±Ø¨Ø³ØªØ§Ù†":"SA","Ø³Ø¹ÙˆØ¯ÛŒ":"SA",
    "iaea":"IA","Ø¢Ú˜Ø§Ù†Ø³":"IA","Ú¯Ø±ÙˆØ³ÛŒ":"IA",
}

ACTION_MAP = {
    # Ù…ÙˆØ´Ú© / Ù¾Ù‡Ù¾Ø§Ø¯
    "missile":"MSL","missiles":"MSL","rocket":"MSL","rockets":"MSL",
    "ballistic":"MSL","cruise missile":"MSL","hypersonic":"MSL",
    "drone":"MSL","uav":"MSL","shaheed":"MSL","shahed":"MSL",
    "launch":"MSL","launched":"MSL","fire":"MSL","fires":"MSL","fired":"MSL",
    "Ù…ÙˆØ´Ú©":"MSL","Ø±Ø§Ú©Øª":"MSL","Ù¾Ù‡Ù¾Ø§Ø¯":"MSL","Ø´Ù„ÛŒÚ©":"MSL","Ù¾Ø±ØªØ§Ø¨":"MSL",
    # Ø­Ù…Ù„Ù‡ Ù‡ÙˆØ§ÛŒÛŒ
    "airstrike":"AIR","airstrikes":"AIR","air strike":"AIR","air raid":"AIR",
    "bombing":"AIR","bombed":"AIR","warplane":"AIR","jet":"AIR","f-35":"AIR",
    "b-52":"AIR","b-1":"AIR","b-2":"AIR","f-15":"AIR","f-16":"AIR",
    "Ø¨Ù…Ø¨Ø§Ø±Ø§Ù†":"AIR","Ø­Ù…Ù„Ù‡ Ù‡ÙˆØ§ÛŒÛŒ":"AIR","Ø¬Ù†Ú¯Ù†Ø¯Ù‡":"AIR",
    # Ø­Ù…Ù„Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ / Ø¹Ù…Ù„ÛŒØ§Øª
    "strike":"ATK","struck":"ATK","attack":"ATK","attacked":"ATK",
    "assault":"ATK","operation":"ATK","offensive":"ATK",
    "order":"ATK","orders":"ATK","target":"ATK","targeted":"ATK",
    "Ø­Ù…Ù„Ù‡":"ATK","Ø¶Ø±Ø¨Ù‡":"ATK","Ø¹Ù…Ù„ÛŒØ§Øª":"ATK","Ù‡Ø¯Ù":"ATK","Ø²Ø¯":"ATK",
    # Ú©Ø´ØªÙ‡ / ØªÙ„ÙØ§Øª
    "kill":"KIA","killed":"KIA","dead":"KIA","death":"KIA","casualties":"KIA",
    "assassinat":"KIA","martyr":"KIA","martyred":"KIA","fatalities":"KIA",
    "Ú©Ø´ØªÙ‡":"KIA","Ø´Ù‡ÛŒØ¯":"KIA","ØªÙ„ÙØ§Øª":"KIA","Ù…Ø±Ú¯":"KIA","ØªØ±ÙˆØ±":"KIA",
    # Ø¯ÙØ§Ø¹ / Ø±Ù‡Ú¯ÛŒØ±ÛŒ
    "intercept":"DEF","intercepted":"DEF","shot down":"DEF","shoot down":"DEF",
    "iron dome":"DEF","arrow":"DEF","david sling":"DEF","air defense":"DEF",
    "s-300":"DEF","s-400":"DEF","patriot":"DEF",
    "Ø±Ù‡Ú¯ÛŒØ±ÛŒ":"DEF","Ø³Ø±Ù†Ú¯ÙˆÙ†":"DEF","Ù¾Ø¯Ø§ÙÙ†Ø¯":"DEF","Ú¯Ù†Ø¨Ø¯ Ø¢Ù‡Ù†ÛŒÙ†":"DEF",
    # ØªÙ‡Ø¯ÛŒØ¯
    "threat":"THR","threatens":"THR","threaten":"THR","warn":"THR","warning":"THR",
    "ultimatum":"THR","red line":"THR","consequences":"THR",
    "ØªÙ‡Ø¯ÛŒØ¯":"THR","Ù‡Ø´Ø¯Ø§Ø±":"THR","Ø®Ø· Ù‚Ø±Ù…Ø²":"THR",
    # ØªØ­Ø±ÛŒÙ…
    "sanction":"SAN","sanctions":"SAN","embargo":"SAN","freeze":"SAN",
    "ØªØ­Ø±ÛŒÙ…":"SAN","ØªØ­Ø±ÛŒÙ…â€ŒÙ‡Ø§":"SAN","Ù…Ø­Ø§ØµØ±Ù‡":"SAN",
    # Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ
    "nuclear":"NUC","uranium":"NUC","natanz":"NUC","fordow":"NUC",
    "arak":"NUC","enrichment":"NUC","centrifuge":"NUC","plutonium":"NUC",
    "Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ":"NUC","Ù†Ø·Ù†Ø²":"NUC","ÙØ±Ø¯Ùˆ":"NUC","Ø§Ø±Ø§Ú©":"NUC","Ø§ÙˆØ±Ø§Ù†ÛŒÙˆÙ…":"NUC",
    # Ù…Ø°Ø§Ú©Ø±Ù‡ / Ø¯ÛŒÙ¾Ù„Ù…Ø§Ø³ÛŒ
    "negotiat":"DIP","ceasefire":"DIP","deal":"DIP","diplomacy":"DIP",
    "talks":"DIP","agreement":"DIP","truce":"DIP",
    "Ù…Ø°Ø§Ú©Ø±Ù‡":"DIP","Ø¢ØªØ´â€ŒØ¨Ø³":"DIP","ØªÙˆØ§ÙÙ‚":"DIP","Ø¯ÛŒÙ¾Ù„Ù…Ø§Ø³ÛŒ":"DIP",
}

_STOP_EN = {"the","a","an","is","in","of","to","and","or","for","on","at",
            "by","with","from","that","this","has","are","was","were","it","not","but","be","been"}
_STOP_FA = {"Ø¯Ø±","Ùˆ","Ø§Ø²","Ø¨Ù‡","Ø¨Ø§","Ø±Ø§","Ú©Ù‡","Ø§ÛŒÙ†","Ø¢Ù†","ÛŒØ§","Ù‡Ù…","Ù†ÛŒØ²","Ù‡Ø±","Ø§Ù…Ø§","Ø§Ú¯Ù‡","Ø§Ú¯Ø±"}

def _stem(w: str) -> str:
    """Stemming Ø³Ø§Ø¯Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"""
    for sfx in ("tion","ment","ing","ness","ity","ies","ed","es","s"):
        if w.endswith(sfx) and len(w) - len(sfx) > 3:
            return w[:-len(sfx)]
    return w

def _extract_triple(text: str) -> frozenset:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ (WHO, ACTION) Ø§Ø² Ù…ØªÙ† â€” Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù…Ø¹Ù†Ø§ÛŒÛŒ"""
    full = re.sub(r"[^\w\u0600-\u06FF\s]", " ", text.lower())
    actors  = set()
    actions = set()
    # multi-word match Ø§ÙˆÙ„ (Ù…Ù‡Ù…â€ŒØªØ±)
    for phrase, code in sorted(WHO_MAP.items(),    key=lambda x: -len(x[0])):
        if phrase in full: actors.add(code)
    for phrase, code in sorted(ACTION_MAP.items(), key=lambda x: -len(x[0])):
        if phrase in full: actions.add(code)
    return frozenset(actors | actions)

def _stemmed_tokens(text: str) -> set:
    text = re.sub(r"[^\w\u0600-\u06FF\s]", " ", text.lower())
    stop = _STOP_EN | _STOP_FA
    return {_stem(w) for w in text.split() if w and w not in stop and len(w) > 2}

def _stemmed_jaccard(a: str, b: str) -> float:
    s1, s2 = _stemmed_tokens(a), _stemmed_tokens(b)
    return len(s1 & s2) / len(s1 | s2) if s1 and s2 else 0.0

def is_duplicate_story(title_a: str, title_b: str) -> bool:
    """
    ØªØ´Ø®ÛŒØµ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù† Ø®Ø¨Ø± Ø¨ÛŒÙ† Ø¯Ùˆ Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ù…Ø®ØªÙ„Ù
    Ø³Ù‡ Ù„Ø§ÛŒÙ‡:
    1. Entity triple â€” actor Ù…Ø´ØªØ±Ú© + macro-category Ù…Ø´ØªØ±Ú©
    2. Entity triple â€” actor Ù…Ø´ØªØ±Ú© + Ù‡Ø± event code Ù…Ø´ØªØ±Ú©
    3. Stemmed Jaccard â‰¥ JACCARD_THRESHOLD (fallback)
    """
    ta = _extract_triple(title_a)
    tb = _extract_triple(title_b)

    if len(ta) >= 2 and len(tb) >= 2:
        actors_a = {x for x in ta if len(x) == 2}
        actors_b = {x for x in tb if len(x) == 2}
        evts_a   = {x for x in ta if len(x) == 3}
        evts_b   = {x for x in tb if len(x) == 3}

        if actors_a & actors_b:
            # Ù„Ø§ÛŒÙ‡ Û±: macro-category â€” "fires missiles" vs "launches attack" = Ù‡Ù…ÙˆÙ† Ø±ÙˆÛŒØ¯Ø§Ø¯
            macro_a = bool(evts_a & _VIOLENCE_CODES) + bool(evts_a & _POLITICAL_CODES)
            macro_b = bool(evts_b & _VIOLENCE_CODES) + bool(evts_b & _POLITICAL_CODES)
            if macro_a and macro_b:
                v_match = bool(evts_a & _VIOLENCE_CODES) and bool(evts_b & _VIOLENCE_CODES)
                p_match = bool(evts_a & _POLITICAL_CODES) and bool(evts_b & _POLITICAL_CODES)
                if v_match or p_match:
                    return True

            # Ù„Ø§ÛŒÙ‡ Û²: exact event code match
            if evts_a & evts_b:
                return True

    # Ù„Ø§ÛŒÙ‡ Û³: Stemmed Jaccard
    return _stemmed_jaccard(title_a, title_b) >= JACCARD_THRESHOLD


# â”€â”€ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ story fingerprintâ€ŒÙ‡Ø§
# Ù‡Ø± Ø¢ÛŒØªÙ…: {"fps": [fp1,fp2,...], "t": timestamp}
# fp = frozenset â†’ list Ø¨Ø±Ø§ÛŒ JSON

STORY_FILE = "stories.json"
STORY_TTL  = 7200   # 2 Ø³Ø§Ø¹Øª (Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ´Ø´ Ø§Ø®Ø¨Ø§Ø± Ø¬Ù†Ú¯ÛŒ)

def load_stories() -> list[dict]:
    try:
        if Path(STORY_FILE).exists():
            data = json.load(open(STORY_FILE))
            cutoff = datetime.now(timezone.utc).timestamp() - STORY_TTL
            return [x for x in data if x.get("t", 0) > cutoff]
    except: pass
    return []

def save_stories(records: list[dict]):
    json.dump(records[-4000:], open(STORY_FILE, "w"))

def is_story_dup(title: str, stories: list[dict]) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù† Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ù‡Ù…Ù‡ Ø¯Ø§Ø³ØªØ§Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±"""
    for s in stories:
        if is_duplicate_story(title, s.get("title", "")):
            return True
    return False

def register_story(title: str, stories: list[dict]) -> list[dict]:
    """Ø«Ø¨Øª Ø¯Ø§Ø³ØªØ§Ù† Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ù„ÛŒØ³Øª"""
    stories.append({"title": title, "t": datetime.now(timezone.utc).timestamp()})
    return stories



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COMMON_UA = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; rv:121.0) Gecko/20100101 Firefox/121.0 WarBot/13"}

async def fetch_rss(client: httpx.AsyncClient, feed: dict) -> list:
    """
    ÙˆØ§Ú©Ø´ÛŒ RSS Ø¨Ø§ ETag/If-Modified-Since:
    - 304 = ØªØºÛŒÛŒØ± Ù†Ú©Ø±Ø¯Ù‡ â†’ skip (ØµÙØ± bandwidth)
    - 200 = parse Ú©Ø§Ù…Ù„ â†’ Ù‡Ù…Ù‡ entries (ÙÛŒÙ„ØªØ± is_fresh Ø¯Ø± main)
    timeout Ú©ÙˆØªØ§Ù‡ â†’ fail fast â†’ Ø³Ø±Ø¹Øª Ú©Ù„ÛŒ Ø¨Ø§Ù„Ø§ØªØ±
    """
    try:
        hdrs = dict(COMMON_UA)
        if feed.get("_etag"):     hdrs["If-None-Match"]     = feed["_etag"]
        if feed.get("_last_mod"): hdrs["If-Modified-Since"] = feed["_last_mod"]

        r = await client.get(feed["u"],
                             timeout=httpx.Timeout(connect=4.0, read=RSS_TIMEOUT,
                                                   write=4.0, pool=4.0),
                             headers=hdrs)
        if r.status_code == 304: return []
        if r.status_code != 200: return []

        if r.headers.get("ETag"):          feed["_etag"]     = r.headers["ETag"]
        if r.headers.get("Last-Modified"): feed["_last_mod"] = r.headers["Last-Modified"]

        entries = feedparser.parse(r.text).entries or []
        is_emb  = id(feed) in EMBASSY_SET
        return [(e, feed["n"], "rss", is_emb) for e in entries]
    except Exception:
        return []





async def fetch_telegram_channel(client:httpx.AsyncClient, label:str, handle:str) -> list:
    url = f"https://t.me/s/{handle}"
    try:
        r = await client.get(url, timeout=httpx.Timeout(12.0), headers=TG_HEADERS)
        if r.status_code not in (200,301,302): return []
        soup = BeautifulSoup(r.text,"html.parser")
        msgs = soup.select(".tgme_widget_message_wrap")
        if not msgs: return []

        results = []
        cutoff  = get_cutoff(TG_CUTOFF_HOURS)

        for msg in msgs[-20:]:
            txt_el = msg.select_one(".tgme_widget_message_text")
            text   = txt_el.get_text(" ",strip=True) if txt_el else ""
            if not text or len(text)<15: continue

            time_el  = msg.select_one("time")
            dt_str   = time_el.get("datetime","") if time_el else ""
            entry_dt = None
            if dt_str:
                try: entry_dt = datetime.fromisoformat(dt_str.replace("Z","+00:00"))
                except: pass

            if entry_dt and entry_dt < cutoff: continue

            link_el = msg.select_one("a.tgme_widget_message_date")
            link    = link_el.get("href","") if link_el else f"https://t.me/{handle}"

            entry = {"title":text[:200],"summary":text[:600],"link":link,"_tg_dt":entry_dt}
            results.append((entry, label, "tg", False))

        return results
    except Exception as e:
        log.debug(f"TG {handle}: {e}")
        return []






async def fetch_all(client: httpx.AsyncClient, tw_idx: int = 0) -> list:
    """
    ÙˆØ§Ú©Ø´ÛŒ Ù…ÙˆØ§Ø²ÛŒ Ù‡Ù…Ù‡ Ù…Ù†Ø§Ø¨Ø¹:
    - RSS: conditional GET (ETag) â†’ Ø³Ø±ÛŒØ¹â€ŒØªØ±
    - TG: Ø¢Ø®Ø±ÛŒÙ† Û²Û° Ù¾Ø³Øª Ù‡Ø± Ú©Ø§Ù†Ø§Ù„
    - Twitter: ÙÙ‚Ø· TW_HANDLES_PER_RUN handle (rotating) â†’ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² rate-limit
    """
    # â”€â”€ Nitter + RSSHub pool
    log.info("ğ• Probing Twitter sources...")
    await build_twitter_pools(client)
    log.info(f"ğ• Nitter:{len(_nitter_pool)} | RSSHub:{len(_rsshub_pool)} | handles {tw_idx}â€“{tw_idx+TW_HANDLES_PER_RUN}/{len(TWITTER_HANDLES)}")

    # â”€â”€ Twitter: rotating window
    handles_this_run = (TWITTER_HANDLES * 2)[tw_idx: tw_idx + TW_HANDLES_PER_RUN]

    # â”€â”€ Ù‡Ù…Ù‡ taskâ€ŒÙ‡Ø§ Ù…ÙˆØ§Ø²ÛŒ
    rss_t = [fetch_rss(client, f) for f in ALL_RSS_FEEDS]
    tg_t  = [fetch_telegram_channel(client, l, h) for l, h in TELEGRAM_CHANNELS]
    tw_t  = [fetch_twitter(client, l, h) for l, h in handles_this_run]

    all_res = await asyncio.gather(*rss_t, *tg_t, *tw_t, return_exceptions=True)

    out = []; rss_ok = tg_ok = tw_ok = 0
    n_rss = len(ALL_RSS_FEEDS); n_tg = len(TELEGRAM_CHANNELS)

    for i, res in enumerate(all_res):
        if not isinstance(res, list): continue
        out.extend(res)
        if   i < n_rss:            rss_ok += bool(res)
        elif i < n_rss + n_tg:     tg_ok  += bool(res)
        else:                      tw_ok  += bool(res)

    log.info(f"  ğŸ“¡ RSS:{rss_ok}/{len(ALL_RSS_FEEDS)}  ğŸ“¢ TG:{tg_ok}/{len(TELEGRAM_CHANNELS)}  ğ•:{tw_ok}/{len(handles_this_run)}")
    return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini 7 Ù…Ø¯Ù„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GEMINI_BASE = "https://generativelanguage.googleapis.com/v1beta/models"
GEMINI_POOL = [
    {"id":"gemini-2.5-flash-lite",                 "rpd":1000,"tier":1},
    {"id":"gemini-2.5-flash-lite-preview-09-2025", "rpd":1000,"tier":1},
    {"id":"gemini-2.5-flash",                      "rpd": 250,"tier":2},
    {"id":"gemini-2.5-flash-preview-09-2025",      "rpd": 250,"tier":2},
    {"id":"gemini-3-flash-preview",                "rpd": 100,"tier":3},
    {"id":"gemini-2.5-pro",                        "rpd": 100,"tier":3},
    {"id":"gemini-3-pro-preview",                  "rpd":  50,"tier":3},
]

def load_gstate():
    try:
        if Path(GEMINI_STATE_FILE).exists():
            s=json.load(open(GEMINI_STATE_FILE))
            if s.get("date")==datetime.now(timezone.utc).strftime("%Y-%m-%d"): return s
    except: pass
    return {"date":datetime.now(timezone.utc).strftime("%Y-%m-%d"),"usage":{},"fails":{}}

def save_gstate(s): json.dump(s,open(GEMINI_STATE_FILE,"w"))

def pick_models(s):
    r=[]
    for t in [1,2,3]:
        for m in GEMINI_POOL:
            if m["tier"]==t and s["usage"].get(m["id"],0)<m["rpd"] and s["fails"].get(m["id"],0)<3:
                r.append(m)
    return r or GEMINI_POOL

TRANSLATE_PROMPT = """ØªÙˆ ÛŒÙ‡ Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± Ø¬Ù†Ú¯ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù‡Ø³ØªÛŒ. Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø¬Ù†Ú¯ÛŒ Ø±Ùˆ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ú¯Ø±Ø¯ÙˆÙ†.

Ù‚ÙˆØ§Ù†ÛŒÙ† Ø³Ø®Øª:
Û±. ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ§Ù† â€” Ø§Ù…Ø§ Ú©Ø§Ù…Ù„ Ùˆ Ø¯Ù‚ÛŒÙ‚
Û². Ù†Ù‚Ù„â€ŒÙ‚ÙˆÙ„â€ŒÙ‡Ø§ Ø±Ùˆ Ø¹ÛŒÙ†â€ŒØ§Ù„Ø¹ÛŒÙ† Ø¨Ø°Ø§Ø±: Â«Ø¹ÛŒÙ† Ø¬Ù…Ù„Ù‡ Ú¯ÙØªÙ‡â€ŒØ´Ø¯Ù‡Â»
Û³. Ø§Ø³Ø§Ù…ÛŒ Ø±Ùˆ Ø¯Ù‚ÛŒÙ‚ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†: Netanyahu=Ù†ØªØ§Ù†ÛŒØ§Ù‡ÙˆØŒ Khamenei=Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒØŒ IRGC=Ø³Ù¾Ø§Ù‡ØŒ IDF=Ø§Ø±ØªØ´ Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„
Û´. Ø¢Ù…Ø§Ø± Ùˆ Ø§Ø¹Ø¯Ø§Ø¯ Ø±Ùˆ Ø­ÙØ¸ Ú©Ù†: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø´ØªÙ‡ØŒ ÙØ§ØµÙ„Ù‡ØŒ Ø²Ù…Ø§Ù†
Ûµ. Ù‡ÛŒÚ† Ú†ÛŒØ²ÛŒ Ø§Ø² Ø®Ø¨Ø± Ø±Ùˆ Ø­Ø°Ù Ù†Ú©Ù† â€” Ø®Ù„Ø§ØµÙ‡ Ù†Ú©Ù†
Û¶. Ø§Ú¯Ù‡ Ø®Ø¨Ø± Ú©ÙˆØªØ§Ù‡Ù‡ØŒ Ù‡Ù…Ù‡â€ŒØ§Ø´ Ø±Ùˆ Ø¨Ù†ÙˆÛŒØ³
Û·. Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø§ÙˆÙ„ Ø¬Ù…Ù„Ù‡: ğŸ”´=Ø­Ù…Ù„Ù‡/Ú©Ø´ØªÙ‡  ğŸ’¥=Ø§Ù†ÙØ¬Ø§Ø±  ğŸš€=Ù…ÙˆØ´Ú©/Ù¾Ù‡Ù¾Ø§Ø¯  â˜¢ï¸=Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ  âœˆï¸=Ù‡ÙˆØ§ÛŒÛŒ  âš ï¸=ØªÙ‡Ø¯ÛŒØ¯  ğŸ¤=Ù…Ø°Ø§Ú©Ø±Ù‡  ğŸ’°=ØªØ­Ø±ÛŒÙ…  ğŸ›¡ï¸=Ø±Ù‡Ú¯ÛŒØ±ÛŒ  ğŸ“¡=Ø®Ø¨Ø± Ø±Ø³Ù…ÛŒ

Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³Øª:
- Â«ğŸ”´ Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ Ø¨Ø§ Û±Û² Ù…ÙˆØ´Ú© Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ù‡ÙˆØ§ÛŒÛŒ Ø¨Ù†Ø¯Ø±Ø¹Ø¨Ø§Ø³ Ø­Ù…Ù„Ù‡ Ú©Ø±Ø¯. Ø³Ù¾Ø§Ù‡: Û³ Ù†ÙØ± Ø´Ù‡ÛŒØ¯ Ø´Ø¯Ù†Ø¯. Ø¢Ù…Ø±ÛŒÚ©Ø§ Ø§Ø¹Ù„Ø§Ù… Ú©Ø±Ø¯ Ø§Ø² Ø§ÛŒÙ† Ø­Ù…Ù„Ù‡ Ø¨ÛŒâ€ŒØ®Ø¨Ø± Ø¨ÙˆØ¯Ù‡.Â»
- Â«âš ï¸ Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø³Ø®Ù†Ø±Ø§Ù†ÛŒ Ú¯ÙØª: Â«Ø§Ú¯Ù‡ Ø¢Ù…Ø±ÛŒÚ©Ø§ ÙˆØ§Ø±Ø¯ Ø§ÛŒÙ† Ø¬Ù†Ú¯ Ø¨Ø´Ù‡ØŒ Ù‡Ù…Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§Ø´Ùˆ Ø¯Ø± Ø®Ø§ÙˆØ±Ù…ÛŒØ§Ù†Ù‡ Ù‡Ø¯Ù Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ….Â»Â»
- Â«ğŸš€ Ø³Ù†ØªÚ©Ø§Ù… ØªØ£ÛŒÛŒØ¯ Ú©Ø±Ø¯: Ø±Ø§Ø¯Ø§Ø± Ù¾Ø§ØªØ±ÛŒÙˆØª Ø¯Ø± Ù‚Ø·Ø± ÛŒÙ‡ Ù…ÙˆØ´Ú© Ø¨Ø§Ù„Ø³ØªÛŒÚ© Ø§ÛŒØ±Ø§Ù†ÛŒ Ø±Ùˆ Ø¯Ø± Ø§Ø±ØªÙØ§Ø¹ Û¸Û° Ú©ÛŒÙ„ÙˆÙ…ØªØ±ÛŒ Ø±Ù‡Ú¯ÛŒØ±ÛŒ Ú©Ø±Ø¯.Â»

ÙØ±Ù…Øª Ø®Ø±ÙˆØ¬ÛŒ:
###ITEM_0###
[Ø®Ø¨Ø± ÙØ§Ø±Ø³ÛŒ Ú©Ø§Ù…Ù„]
###ITEM_1###
[Ø®Ø¨Ø± ÙØ§Ø±Ø³ÛŒ Ú©Ø§Ù…Ù„]

===Ø®Ø¨Ø±Ù‡Ø§===
{items}"""


async def translate_batch(client:httpx.AsyncClient, articles:list) -> list:
    if not GEMINI_API_KEY or not articles: return articles
    items_txt = "".join(f"###ITEM_{i}###\nTITLE: {t[:400]}\nBODY: {s[:800]}\n" for i,(t,s) in enumerate(articles))
    payload = {"contents":[{"parts":[{"text":TRANSLATE_PROMPT.format(items=items_txt)}]}],
               "generationConfig":{"temperature":0.1,"maxOutputTokens":8192}}
    state = load_gstate()

    for m in pick_models(state):
        mid=m["id"]; used=state["usage"].get(mid,0)
        url=f"{GEMINI_BASE}/{mid}:generateContent?key={GEMINI_API_KEY}"
        log.info(f"ğŸŒ Gemini [{mid[:28]}] {used}/{m['rpd']}")
        for _ in range(2):
            try:
                r = await client.post(url, json=payload, timeout=httpx.Timeout(90.0))
                if r.status_code==200:
                    raw = r.json()["candidates"][0]["content"]["parts"][0]["text"]
                    res = _parse_tr(raw, articles)
                    state["usage"][mid]=used+1; state["fails"][mid]=0
                    save_gstate(state)
                    return res
                elif r.status_code==429:
                    w=int(r.headers.get("Retry-After","30"))
                    state["fails"][mid]=state["fails"].get(mid,0)+1
                    await asyncio.sleep(min(w,15)); break
                else: break
            except asyncio.TimeoutError: break
            except: break

    save_gstate(state)
    return articles

def _parse_tr(raw:str, fallback:list) -> list:
    results=list(fallback)
    for m in re.finditer(r'###ITEM_(\d+)###\s*\n(.+?)(?=###ITEM_|\Z)',raw,re.DOTALL):
        idx=int(m.group(1)); text=m.group(2).strip().replace("**","").replace("*","")
        if 0<=idx<len(results) and text: results[idx]=(nfa(text),"")
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_html(t:str) -> str:
    return BeautifulSoup(str(t or ""),"html.parser").get_text(" ",strip=True)

def make_id(entry:dict) -> str:
    k=entry.get("link") or entry.get("id") or entry.get("title") or ""
    return hashlib.md5(k.encode()).hexdigest()

def format_dt(entry:dict) -> str:
    try:
        t=entry.get("published_parsed") or entry.get("updated_parsed")
        if t: return datetime(*t[:6],tzinfo=timezone.utc).astimezone(TEHRAN_TZ).strftime("ğŸ• %H:%M  |  %d %b")
        tg_dt=entry.get("_tg_dt")
        if tg_dt: return tg_dt.astimezone(TEHRAN_TZ).strftime("ğŸ• %H:%M  |  %d %b")
    except: pass
    return datetime.now(TEHRAN_TZ).strftime("ğŸ• %H:%M")

def esc(t:str) -> str: return (t or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")
def trim(t:str, n:int) -> str:
    t=re.sub(r'\s+',' ',t).strip()
    return t if len(t)<=n else t[:n].rsplit(" ",1)[0]+"â€¦"

def load_seen() -> set:
    if Path(SEEN_FILE).exists():
        try: return set(json.load(open(SEEN_FILE)))
        except: pass
    return set()

def save_seen(seen: set):
    json.dump(list(seen)[-30000:], open(SEEN_FILE, "w"))

# â”€â”€ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø§Ø¬Ø±Ø§ Ø¨Ø±Ø§ÛŒ cutoff Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ â”€â”€
RUN_STATE_FILE      = "run_state.json"
REALTIME_BUFFER_MIN = 0     # ØµÙØ± buffer â†’ Ø§ÙˆÙ„ÛŒÙ† Ù†ÙØ± Ø¨ÙˆØ¯Ù† (ÙØ§ØµÙ„Ù‡ RSS Ø¹Ø§Ø¯ØªØ§Ù‹ â‰¤2min)
MAX_LOOKBACK_MIN    = 30    # Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§: Û³Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Ø¹Ù‚Ø¨

def load_last_run() -> tuple[datetime, int]:
    """(Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø§Ø¬Ø±Ø§ØŒ twitter rotation index)"""
    try:
        if Path(RUN_STATE_FILE).exists():
            d   = json.load(open(RUN_STATE_FILE))
            ts  = d.get("last_run", 0)
            idx = int(d.get("tw_idx", 0))
            if ts:
                return datetime.fromtimestamp(ts, tz=timezone.utc), idx
    except: pass
    # Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§ â†’ Û³Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Ø¹Ù‚Ø¨
    return datetime.now(timezone.utc) - timedelta(minutes=MAX_LOOKBACK_MIN), 0

def save_last_run(tw_idx: int = 0):
    existing = {}
    try:
        if Path(RUN_STATE_FILE).exists():
            existing = json.load(open(RUN_STATE_FILE))
    except: pass
    existing.update({"last_run": datetime.now(timezone.utc).timestamp(), "tw_idx": tw_idx})
    json.dump(existing, open(RUN_STATE_FILE, "w"))

def get_realtime_cutoff() -> tuple[datetime, int]:
    """
    (cutoff Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ØŒ twitter rotation index)
    cutoff = Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø§Ø¬Ø±Ø§ (Ø¨Ø¯ÙˆÙ† buffer)
    Ø¯Ø± Ø¹Ù…Ù„ RSS/TG itemÙ‡Ø§ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ run Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´Ù†
    """
    last, tw_idx = load_last_run()
    # cutoff = Ø¢Ø®Ø±ÛŒÙ† Ø§Ø¬Ø±Ø§ (Ø¨Ø¯ÙˆÙ† buffer Ù…Ù†ÙÛŒ)
    # Ø­Ø¯Ø§Ú©Ø«Ø± MAX_LOOKBACK_MIN Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø³ÛŒÙ„ Ø®Ø¨Ø± Ø¯Ø± Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§
    cutoff_max = datetime.now(timezone.utc) - timedelta(minutes=MAX_LOOKBACK_MIN)
    return max(last, cutoff_max), tw_idx






# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ØªÙ„Ú¯Ø±Ø§Ù…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TGAPI=f"https://api.telegram.org/bot{BOT_TOKEN}"

async def tg_send_text(client:httpx.AsyncClient, text:str) -> bool:
    for _ in range(4):
        try:
            r=await client.post(f"{TGAPI}/sendMessage", json={
                "chat_id":CHANNEL_ID,"text":text[:MAX_MSG_LEN],
                "parse_mode":"HTML","disable_web_page_preview":True,
            }, timeout=httpx.Timeout(15.0))
            d=r.json()
            if d.get("ok"): return True
            if d.get("error_code")==429: await asyncio.sleep(d.get("parameters",{}).get("retry_after",20))
            elif d.get("error_code") in (400,403): return False
            else: await asyncio.sleep(5)
        except Exception as e: log.warning(f"TG: {e}"); await asyncio.sleep(8)
    return False

async def tg_send_photo(client:httpx.AsyncClient, buf:io.BytesIO, caption:str) -> bool:
    try:
        r=await client.post(f"{TGAPI}/sendPhoto",
            data={"chat_id":CHANNEL_ID,"caption":caption[:1024],"parse_mode":"HTML"},
            files={"photo":("card.jpg",buf,"image/jpeg")},
            timeout=httpx.Timeout(30.0))
        return r.json().get("ok",False)
    except Exception as e: log.warning(f"TG photo: {e}"); return False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ­  ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø¨Ø± Ø¨Ø§ Ø¢ÛŒÚ©ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ
#
#  Ù…Ù†Ø·Ù‚ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ (Ø§Ø² Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒÙ† Ø´Ø¯Øª):
#   Û±. ØªÙ„ÙØ§Øª Ø§Ù†Ø³Ø§Ù†ÛŒ  â†’ ğŸ’€
#   Û². Ø­Ù…Ù„Ù‡ ÙØ¹Ø§Ù„     â†’ ğŸ”´
#   Û³. Ø§Ù†ÙØ¬Ø§Ø±        â†’ ğŸ’¥
#   Û´. Ø­Ù…Ù„Ù‡ Ù‡ÙˆØ§ÛŒÛŒ    â†’ âœˆï¸
#   Ûµ. Ù…ÙˆØ´Ú©/Ù¾Ù‡Ù¾Ø§Ø¯    â†’ ğŸš€
#   Û¶. Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ       â†’ â˜¢ï¸
#   Û·. Ø¯Ø±ÛŒØ§ÛŒÛŒ        â†’ ğŸš¢
#   Û¸. Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ      â†’ ğŸ•µï¸
#   Û¹. Ø¯ÙØ§Ø¹/Ø±Ù‡Ú¯ÛŒØ±ÛŒ   â†’ ğŸ›¡ï¸
#  Û±Û°. ØªØ´Ø¯ÛŒØ¯         â†’ ğŸ”¥
#  Û±Û±. ØªØ­Ø±ÛŒÙ…         â†’ ğŸ’°
#  Û±Û². ØªÙ‡Ø¯ÛŒØ¯         â†’ âš ï¸
#  Û±Û³. Ø¯ÛŒÙ¾Ù„Ù…Ø§Ø³ÛŒ      â†’ ğŸ¤
#  Û±Û´. Ø¨ÛŒØ§Ù†ÛŒÙ‡        â†’ ğŸ“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SENTIMENT_RULES: list[tuple[str, list[str], list[str]]] = [
    # (icon, Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ EN, Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ FA)
    ("ğŸ’€", ["killed","dead","casualties","deaths","fatalities","wounded","injure",
            "martyred","massacre","civilian death","body count"],
           ["Ú©Ø´ØªÙ‡","Ø´Ù‡ÛŒØ¯","Ø´Ù‡Ø¯Ø§","ØªÙ„ÙØ§Øª","Ú©Ø´ØªØ§Ø±","Ù‚Ø±Ø¨Ø§Ù†ÛŒ","Ù…Ø¬Ø±ÙˆØ­","ÙÙˆØª"]),

    ("ğŸ”´", ["attack","struck","assault","offensive","launched attack","opened fire",
            "under attack","targeted","hit by","bombed"],
           ["Ø­Ù…Ù„Ù‡","Ø¶Ø±Ø¨Ù‡","Ø²Ø¯Ù‡ Ø´Ø¯","Ø­Ù…Ù„Ù‡ Ú©Ø±Ø¯","Ù…ÙˆØ±Ø¯ Ù‡Ø¯Ù"]),

    ("ğŸ’¥", ["explosion","blast","detonation","explode","blew up","bomb went off",
            "shockwave","blast wave"],
           ["Ø§Ù†ÙØ¬Ø§Ø±","Ù…Ù†ÙØ¬Ø±","Ø§Ù†ÙØ¬Ø§Ø± Ø¨Ø²Ø±Ú¯","ØµØ¯Ø§ÛŒ Ø§Ù†ÙØ¬Ø§Ø±","ØªØ±Ú©ÛŒØ¯"]),

    ("âœˆï¸", ["airstrike","air strike","air raid","aerial bombardment","jet","fighter jet",
            "bombing raid","warplane","f-35","f-15","f-16","b-52","b-2","b-1"],
           ["Ø­Ù…Ù„Ù‡ Ù‡ÙˆØ§ÛŒÛŒ","Ø¨Ù…Ø¨Ø§Ø±Ø§Ù†","Ø¬Ù†Ú¯Ù†Ø¯Ù‡","Ù‡ÙˆØ§Ù¾ÛŒÙ…Ø§ÛŒ Ø¬Ù†Ú¯ÛŒ","Ù‡ÙˆØ§ÛŒÛŒ"]),

    ("ğŸš€", ["missile","rocket","ballistic","cruise missile","drone strike",
            "uav attack","unmanned","hypersonic","icbm","projectile"],
           ["Ù…ÙˆØ´Ú©","Ù¾Ù‡Ù¾Ø§Ø¯","Ù…ÙˆØ´Ú© Ø¨Ø§Ù„Ø³ØªÛŒÚ©","Ù…ÙˆØ´Ú© Ú©Ø±ÙˆØ²","Ù¾Ø±ØªØ§Ø¨ Ù…ÙˆØ´Ú©","Ø±Ø§Ú©Øª"]),

    ("â˜¢ï¸", ["nuclear","uranium","enrichment","natanz","fordow","arak","centrifuge",
            "radioactive","dirty bomb","atomic","plutonium","iaea","npt"],
           ["Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ","Ø§ØªÙ…ÛŒ","Ø§ÙˆØ±Ø§Ù†ÛŒÙˆÙ…","ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ","Ù†Ø·Ù†Ø²","ÙØ±Ø¯Ùˆ","Ø§Ø±Ø§Ú©","Ø³Ø§Ù†ØªØ±ÛŒÙÛŒÙˆÚ˜","Ù‡Ø³ØªÙ‡"]),

    ("ğŸš¢", ["navy","naval","warship","destroyer","aircraft carrier","frigate",
            "submarine","strait of hormuz","red sea","persian gulf patrol","coast guard"],
           ["Ù†ÛŒØ±ÙˆÛŒ Ø¯Ø±ÛŒØ§ÛŒÛŒ","Ù†Ø§ÙˆÚ†Ù‡","Ù†Ø§Ùˆ","Ù†Ø§Ùˆ Ù‡ÙˆØ§Ù¾ÛŒÙ…Ø§Ø¨Ø±","ØªÙ†Ú¯Ù‡ Ù‡Ø±Ù…Ø²","Ø¯Ø±ÛŒØ§ÛŒÛŒ","Ø®Ù„ÛŒØ¬ ÙØ§Ø±Ø³"]),

    ("ğŸ•µï¸", ["intelligence","mossad","cia","spy","covert","assassination","sabotage",
            "cyber attack","hacking","infiltrat","agent","operativ"],
           ["Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ","Ø¬Ø§Ø³ÙˆØ³ÛŒ","Ù…ÙˆØ³Ø§Ø¯","Ø¹Ù…Ù„ÛŒØ§Øª Ù…Ø®ÙÛŒ","Ø®Ø±Ø§Ø¨Ú©Ø§Ø±ÛŒ","ØªØ±ÙˆØ±","Ø³Ø§ÛŒØ¨Ø±ÛŒ","Ù†ÙÙˆØ°"]),

    ("ğŸ›¡ï¸", ["intercept","shot down","iron dome","arrow missile","david sling",
            "air defense","patriot","s-300","s-400","anti-missile","shoot down"],
           ["Ø±Ù‡Ú¯ÛŒØ±ÛŒ","Ù¾Ø¯Ø§ÙÙ†Ø¯","Ú¯Ù†Ø¨Ø¯ Ø¢Ù‡Ù†ÛŒÙ†","Ø³Ø±Ù†Ú¯ÙˆÙ† Ú©Ø±Ø¯","Ø³Ø§Ù…Ø§Ù†Ù‡ Ù…ÙˆØ´Ú©ÛŒ","Ø¶Ø¯ Ù…ÙˆØ´Ú©"]),

    ("ğŸ”¥", ["escalat","escalation","tension","brink of war","imminent","standoff",
            "heighten","provocation","retaliat","tit for tat","cross the line"],
           ["ØªØ´Ø¯ÛŒØ¯","ØªÙ†Ø´","Ø¢Ø³ØªØ§Ù†Ù‡ Ø¬Ù†Ú¯","ØªÙ„Ø§ÙÛŒ","Ù„Ø¨Ù‡ Ù¾Ø±ØªÚ¯Ø§Ù‡","Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´"]),

    ("ğŸ’°", ["sanction","embargo","freeze assets","economic pressure","export ban",
            "oil ban","swift","financial restriction","maximum pressure"],
           ["ØªØ­Ø±ÛŒÙ…","ØªØ­Ø±ÛŒÙ…â€ŒÙ‡Ø§","Ù…Ø­Ø§ØµØ±Ù‡ Ø§Ù‚ØªØµØ§Ø¯ÛŒ","ÙØ´Ø§Ø± Ø§Ù‚ØªØµØ§Ø¯ÛŒ","Ù…Ø³Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒ"]),

    ("âš ï¸", ["threat","warn","warning","ultimatum","red line","consequences",
            "take action","will respond","prepare for","on alert"],
           ["ØªÙ‡Ø¯ÛŒØ¯","Ù‡Ø´Ø¯Ø§Ø±","Ø®Ø· Ù‚Ø±Ù…Ø²","Ø§ÙˆÙ„ØªÛŒÙ…Ø§ØªÙˆÙ…","Ø¹ÙˆØ§Ù‚Ø¨","Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ¨Ø§Ø´","ÙˆØ§Ú©Ù†Ø´ Ù†Ø´Ø§Ù†"]),

    ("ğŸ¤", ["negotiation","talks","deal","diplomacy","ceasefire","agreement",
            "summit","meeting","envoy","dialogue","diplomatic"],
           ["Ù…Ø°Ø§Ú©Ø±Ù‡","ØªÙˆØ§ÙÙ‚","Ø¯ÛŒÙ¾Ù„Ù…Ø§Ø³ÛŒ","Ø¢ØªØ´â€ŒØ¨Ø³","Ú¯ÙØªÚ¯Ùˆ","Ù†Ø´Ø³Øª","Ø¯ÛŒÙ¾Ù„Ù…Ø§ØªÛŒÚ©","Ù…ÛŒØ§Ù†Ø¬ÛŒ"]),

    ("ğŸ“œ", ["statement","declared","announced","said","confirmed","denied",
            "press conference","official","spokesperson","briefing"],
           ["Ø¨ÛŒØ§Ù†ÛŒÙ‡","Ø§Ø¹Ù„Ø§Ù…","Ø§Ø¹Ù„Ø§Ù… Ú©Ø±Ø¯","ØªØ£ÛŒÛŒØ¯ Ú©Ø±Ø¯","Ù†ÙÛŒ Ú©Ø±Ø¯","Ù†Ø´Ø³Øª Ø®Ø¨Ø±ÛŒ","Ø³Ø®Ù†Ú¯Ùˆ"]),
]

def analyze_sentiment(text: str) -> list[str]:
    """
    ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø®Ø¨Ø± Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø¢ÛŒÚ©ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³ÛŒ
    - Ø­Ø¯Ø§Ú©Ø«Ø± Û³ Ø¢ÛŒÚ©ÙˆÙ† Ø¨Ø±Ø¬Ø³ØªÙ‡â€ŒØªØ±ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
    - Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±ØªÛŒØ¨ Ù‚ÙˆØ§Ù†ÛŒÙ† (Ø´Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
    """
    txt = text.lower()
    found: list[str] = []
    for icon, en_kws, fa_kws in SENTIMENT_RULES:
        if any(kw in txt for kw in en_kws) or any(kw in txt for kw in fa_kws):
            found.append(icon)
        if len(found) >= 3:
            break
    return found if found else ["ğŸ“°"]  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ø®Ø¨Ø± Ù…Ø¹Ù…ÙˆÙ„ÛŒ

def sentiment_bar(icons: list[str]) -> str:
    """Ø®Ø· Ù†Ù…Ø§ÛŒØ´ Ø¢ÛŒÚ©ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³ÛŒ"""
    return "  ".join(icons)


async def main():
    global _NITTER_SEMA
    if not BOT_TOKEN or not CHANNEL_ID:
        log.error("âŒ BOT_TOKEN ÛŒØ§ CHANNEL_ID Ù†ÛŒØ³Øª!"); return

    # â”€â”€ Semaphore Ø¨Ø±Ø§ÛŒ Nitter â€” Ù¾Ø³ Ø§Ø² probe Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø§Ù„Ø§ØªØ± OK Ø§Ø³Øª
    _NITTER_SEMA = asyncio.Semaphore(10)   # max 10 Twitter request Ù‡Ù…Ø²Ù…Ø§Ù†

    seen    = load_seen()
    stories = load_stories()
    cutoff, tw_idx = get_realtime_cutoff()

    log.info("=" * 65)
    log.info(f"ğŸš€ WarBot v14  |  {datetime.now(TEHRAN_TZ).strftime('%H:%M ØªÙ‡Ø±Ø§Ù†')}")
    log.info(f"   ğŸ“¡ {len(ALL_RSS_FEEDS)} RSS  ğŸ“¢ {len(TELEGRAM_CHANNELS)} TG  ğ• {len(TWITTER_HANDLES)} TW")
    log.info(f"   ğŸ¨ PIL: {'âœ…' if PIL_OK else 'âŒ'}  |  ğŸ§  Triple+Stemmed dedup")
    log.info(f"   â±  cutoff: {cutoff.astimezone(TEHRAN_TZ).strftime('%H:%M')} ØªÙ‡Ø±Ø§Ù†  |  ğ• idx:{tw_idx}")
    log.info(f"   ğŸ’¾ seen:{len(seen)}  stories:{len(stories)}")
    log.info("=" * 65)

    limits = httpx.Limits(max_connections=80, max_keepalive_connections=30)
    async with httpx.AsyncClient(follow_redirects=True, limits=limits) as client:

        # â”€â”€ ADS-B Ùˆ fetch_all Ù…ÙˆØ§Ø²ÛŒ
        flight_task = asyncio.create_task(fetch_military_flights(client))
        raw_task    = asyncio.create_task(fetch_all(client, tw_idx))
        flight_msgs, raw = await asyncio.gather(flight_task, raw_task)
        log.info(f"ğŸ“¥ {len(raw)} Ø¢ÛŒØªÙ… Ø®Ø§Ù…  âœˆï¸ {len(flight_msgs)} ØªØ­Ø±Ú© Ù‡ÙˆØ§ÛŒÛŒ")

        # â”€â”€ Ù¾Ø±Ø¯Ø§Ø²Ø´ â€” Ø³Ù‡ Ù„Ø§ÛŒÙ‡ dedup
        collected = []
        cnt_old = cnt_irrel = cnt_url = cnt_story = 0

        for entry, src_name, src_type, is_emb in raw:
            eid = make_id(entry)

            # Ù„Ø§ÛŒÙ‡ Û±: URL hash
            if eid in seen:
                cnt_url += 1; continue

            # Ù„Ø§ÛŒÙ‡ Û²: ØªØ§Ø²Ú¯ÛŒ
            if not is_fresh(entry, cutoff):
                seen.add(eid); cnt_old += 1; continue

            t    = clean_html(entry.get("title", ""))
            s    = clean_html(entry.get("summary") or entry.get("description") or "")
            full = f"{t} {s}"

            # Ù„Ø§ÛŒÙ‡ Û³: war relevance
            if not is_war_relevant(full, is_embassy=is_emb,
                                   is_tg=(src_type=="tg"), is_tw=(src_type=="tw")):
                seen.add(eid); cnt_irrel += 1; continue

            # Ù„Ø§ÛŒÙ‡ Û´: story dedup
            if is_story_dup(t, stories):
                seen.add(eid); cnt_story += 1; continue

            collected.append((eid, entry, src_name, src_type, is_emb))
            stories = register_story(t, stories)

        log.info(
            f"ğŸ“Š Ù‚Ø¯ÛŒÙ…ÛŒ:{cnt_old}  Ù†Ø§Ù…Ø±ØªØ¨Ø·:{cnt_irrel}  "
            f"url-dup:{cnt_url}  story-dup:{cnt_story}  âœ… {len(collected)} Ø®Ø¨Ø±"
        )

        # Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø§ÙˆÙ„ØŒ Ø­Ø¯Ø§Ú©Ø«Ø± MAX_NEW_PER_RUN
        collected = list(reversed(collected))
        if len(collected) > MAX_NEW_PER_RUN:
            collected = collected[-MAX_NEW_PER_RUN:]

        # â”€â”€ Ø§Ø±Ø³Ø§Ù„ ØªØ­Ø±Ú©Ø§Øª Ù‡ÙˆØ§ÛŒÛŒ (Ø§ÙˆÙ„ÙˆÛŒØª)
        for msg in flight_msgs[:3]:
            await tg_send_text(client, msg)
            await asyncio.sleep(0.5)

        if not collected:
            log.info("ğŸ’¤ Ø®Ø¨Ø± Ø¬Ù†Ú¯ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ Ù†ÛŒØ³Øª")
            save_seen(seen); save_stories(stories); save_last_run(next_tw_idx); return

        # â”€â”€ ØªØ±Ø¬Ù…Ù‡ Gemini
        arts_in = [
            (trim(clean_html(e.get("title", "")), MAX_TITLE_LEN),
             trim(clean_html(e.get("summary") or e.get("description") or ""), MAX_ARTICLE_LEN))
            for _, e, _, _, _ in collected
        ]
        if GEMINI_API_KEY:
            log.info(f"ğŸŒ ØªØ±Ø¬Ù…Ù‡ {len(arts_in)} Ø®Ø¨Ø±...")
            translations = await translate_batch(client, arts_in)
        else:
            translations = arts_in

        # â”€â”€ Ø§Ø±Ø³Ø§Ù„
        sent = 0
        for i, (eid, entry, src_name, stype, is_emb) in enumerate(collected):
            fa, _    = translations[i]
            en_title = arts_in[i][0]
            en_body  = arts_in[i][1]
            link     = entry.get("link", "")
            dt_str   = format_dt(entry)
            display  = fa if (fa and fa != en_title and len(fa) > 5) else en_title
            urgent   = any(w in (fa + en_title).lower() for w in
                           ["attack","strike","airstrike","killed","bomb","explosion",
                            "Ø­Ù…Ù„Ù‡","Ú©Ø´ØªÙ‡","Ø§Ù†ÙØ¬Ø§Ø±","Ù…ÙˆØ´Ú©","Ø¨Ù…Ø¨Ø§Ø±Ø§Ù†","Ø´Ù‡ÛŒØ¯"])

            # ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª + Ø§Ù‡Ù…ÛŒØª
            sentiment_icons = analyze_sentiment(f"{fa} {en_title} {en_body}")
            s_bar      = sentiment_bar(sentiment_icons)
            importance = calc_importance(en_title, en_body, sentiment_icons, stype)
            src_icon   = "ğŸ›ï¸" if is_emb else ("ğ•" if stype=="tw" else ("ğŸ“¢" if stype=="tg" else "ğŸ“¡"))
            card_sent  = False

            log.info(f"  â†’ [{stype}] imp={importance} {en_title[:55]}")

            if PIL_OK:
                # Ø®Ø¨Ø± Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù… (importance â‰¥ 7): Ú©Ø§Ø±Øª ØºÙ†ÛŒ + article fetch
                if importance >= RICH_CARD_THRESHOLD and link:
                    log.info(f"    ğŸ“° ÙˆØ§Ú©Ø´ÛŒ Ù…Ù‚Ø§Ù„Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Øª ØºÙ†ÛŒ...")
                    article_body = await fetch_article_text(client, link)
                    buf = make_rich_card(en_title, display, article_body,
                                        src_name, dt_str, urgent, sentiment_icons)
                else:
                    article_body = ""
                    buf = make_news_card(en_title, fa if fa != en_title else "",
                                        src_name, dt_str, "", urgent, sentiment_icons)
                if buf:
                    # caption Ø¨Ø§ Ù…ØªÙ† Ú©Ø§Ù…Ù„ ØªØ±Ø¬Ù…Ù‡
                    cap = f"{s_bar}\n\n<b>{esc(display)}</b>"
                    if importance >= RICH_CARD_THRESHOLD:
                        cap += f"\n\n<i>{esc(trim(en_body,300))}</i>"
                    cap += f"\n\n{src_icon} <b>{esc(src_name)}</b>  {dt_str}"
                    if await tg_send_photo(client, buf, cap):
                        card_sent = True

            if not card_sent:
                # Ù…ØªÙ† Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„
                parts = [s_bar, f"<b>{esc(display)}</b>"]
                if en_body and len(en_body) > 30:
                    parts += ["", f"<i>{esc(trim(en_body, 500))}</i>"]
                parts += ["", f"â”€â”€â”€ {src_icon} <b>{esc(src_name)}</b>"]
                if dt_str: parts.append(dt_str)
                if await tg_send_text(client, "\n".join(parts)):
                    card_sent = True

            if card_sent:
                seen.add(eid); sent += 1
                log.info(f"    âœ… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
            await asyncio.sleep(SEND_DELAY)

        save_seen(seen)
        save_stories(stories)
        save_last_run(next_tw_idx)
        log.info(f"ğŸ {sent}/{len(collected)} Ø®Ø¨Ø± | ğ• next={next_tw_idx}")



if __name__=="__main__":
    asyncio.run(main())
