"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        ğŸ›¡ï¸ Military Intel Bot v8 â€” Fixed + Expanded + Hazm               â•‘
â•‘   Iran Â· Israel Â· USA  |  70+ Ù…Ù†Ø¨Ø¹  |  Gemini AI  |  ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os, json, hashlib, asyncio, logging, re
from pathlib import Path
from datetime import datetime, timezone, timedelta
from bs4 import BeautifulSoup
import feedparser, httpx, pytz

# Hazm Ø¨Ø±Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙØ§Ø±Ø³ÛŒ Ø®Ø±ÙˆØ¬ÛŒ AI
try:
    from hazm import Normalizer as HazmNormalizer
    _hazm = HazmNormalizer()
    def normalize_fa(text: str) -> str:
        return _hazm.normalize(text)
except ImportError:
    def normalize_fa(text: str) -> str:
        text = text.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
        return re.sub(r'  +', ' ', text).strip()

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
log = logging.getLogger("MilBot")

BOT_TOKEN      = os.environ.get("BOT_TOKEN", "")
CHANNEL_ID     = os.environ.get("CHANNEL_ID", "")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

SEEN_FILE       = "seen.json"
MAX_NEW_PER_RUN = 20     # Ø¨Ø§ Û±Û° Ø¯Ù‚ÛŒÙ‚Ù‡ interval Ú©Ø§ÙÛŒÙ‡
MAX_MSG_LEN     = 4096
SEND_DELAY      = 2
TEHRAN_TZ       = pytz.timezone("Asia/Tehran")

# Ø³Ø§Ø¹Øª Û³:Û±Û¸ ØªÙ‡Ø±Ø§Ù† (UTC+3:30) = Û²Û³:Û´Û¸ UTC Ø±ÙˆØ² Û²Û± ÙÙˆØ±ÛŒÙ‡
# Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§ÛŒÙ† Ù„Ø­Ø¸Ù‡ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ â€” Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡
NEWS_CUTOFF = datetime(2026, 2, 21, 23, 48, 0, tzinfo=timezone.utc)

RSS_FEEDS = [
    {"name": "ğŸŒ Reuters World",       "url": "https://feeds.reuters.com/reuters/worldNews"},
    {"name": "ğŸŒ Reuters Top",         "url": "https://feeds.reuters.com/reuters/topNews"},
    {"name": "ğŸŒ AP Top News",         "url": "https://feeds.apnews.com/rss/apf-topnews"},
    {"name": "ğŸŒ AP World",            "url": "https://feeds.apnews.com/rss/apf-WorldNews"},
    {"name": "ğŸŒ AP Military",         "url": "https://apnews.com/hub/military-and-defense?format=rss"},
    {"name": "ğŸŒ Bloomberg Politics",  "url": "https://feeds.bloomberg.com/politics/news.rss"},
    {"name": "ğŸŒ WSJ World",           "url": "https://feeds.a.dj.com/rss/RSSWorldNews.xml"},
    {"name": "ğŸŒ NYT World",           "url": "https://rss.nytimes.com/services/xml/rss/nyt/World.rss"},
    {"name": "ğŸŒ CNN Middle East",     "url": "http://rss.cnn.com/rss/edition_meast.rss"},
    {"name": "ğŸŒ CNN World",           "url": "http://rss.cnn.com/rss/edition_world.rss"},
    {"name": "ğŸŒ BBC Middle East",     "url": "http://feeds.bbci.co.uk/news/world/middle_east/rss.xml"},
    {"name": "ğŸŒ BBC World",           "url": "http://feeds.bbci.co.uk/news/world/rss.xml"},
    {"name": "ğŸŒ Al Jazeera English",  "url": "https://www.aljazeera.com/xml/rss/all.xml"},
    {"name": "ğŸŒ Fox News World",      "url": "https://moxie.foxnews.com/google-publisher/world.xml"},
    {"name": "ğŸŒ Politico NatSec",    "url": "https://rss.politico.com/defense.xml"},
    {"name": "ğŸŒ Politico Politics",  "url": "https://rss.politico.com/politics-news.xml"},
    {"name": "ğŸŒ The Hill",           "url": "https://thehill.com/rss/syndicator/19110"},
    {"name": "ğŸ“° Axios NatSec",        "url": "https://api.axios.com/feed/national-security"},
    {"name": "ğŸ“° Axios World",         "url": "https://api.axios.com/feed/world"},
    {"name": "ğŸ“° Axios Top",           "url": "https://api.axios.com/feed/top-stories"},
    {"name": "ğŸ“° Axios Politics",      "url": "https://api.axios.com/feed/politics"},
    {"name": "ğŸ‡ºğŸ‡¸ Pentagon",           "url": "https://www.defense.gov/DesktopModules/ArticleCS/RSS.ashx?ContentType=1&Site=945&max=10"},
    {"name": "ğŸ‡ºğŸ‡¸ CENTCOM",            "url": "https://www.centcom.mil/RSS/"},
    {"name": "ğŸ‡ºğŸ‡¸ USNI News",          "url": "https://news.usni.org/feed"},
    {"name": "ğŸ‡ºğŸ‡¸ Breaking Defense",   "url": "https://breakingdefense.com/feed/"},
    {"name": "ğŸ‡ºğŸ‡¸ Defense News",       "url": "https://www.defensenews.com/arc/outboundfeeds/rss/"},
    {"name": "ğŸ‡ºğŸ‡¸ Military Times",     "url": "https://www.militarytimes.com/arc/outboundfeeds/rss/"},
    {"name": "ğŸ‡ºğŸ‡¸ Stars and Stripes",  "url": "https://www.stripes.com/arc/outboundfeeds/rss/?outputType=xml"},
    {"name": "ğŸ‡ºğŸ‡¸ C4ISRNET",           "url": "https://www.c4isrnet.com/arc/outboundfeeds/rss/"},
    {"name": "ğŸ‡ºğŸ‡¸ The War Zone",       "url": "https://www.thedrive.com/feeds/the-war-zone"},
    {"name": "ğŸ‡ºğŸ‡¸ War on the Rocks",   "url": "https://warontherocks.com/feed/"},
    {"name": "ğŸ‡ºğŸ‡¸ Task & Purpose",     "url": "https://taskandpurpose.com/feed/"},
    {"name": "ğŸ‡ºğŸ‡¸ Janes",              "url": "https://www.janes.com/feeds/news"},
    {"name": "ğŸ‡®ğŸ‡± IDF Official",       "url": "https://www.idf.il/en/mini-sites/idf-spokesperson-english/feed/"},
    {"name": "ğŸ‡®ğŸ‡± Jerusalem Post",     "url": "https://www.jpost.com/rss/rssfeedsmilitary.aspx"},
    {"name": "ğŸ‡®ğŸ‡± Jerusalem Post All", "url": "https://www.jpost.com/rss/rssfeedsheadlines.aspx"},
    {"name": "ğŸ‡®ğŸ‡± Times of Israel",    "url": "https://www.timesofisrael.com/feed/"},
    {"name": "ğŸ‡®ğŸ‡± Haaretz English",    "url": "https://www.haaretz.com/cmlink/1.4455099"},
    {"name": "ğŸ‡®ğŸ‡± Israel Hayom",       "url": "https://www.israelhayom.com/feed/"},
    {"name": "ğŸ‡®ğŸ‡± Ynetnews",           "url": "https://www.ynetnews.com/category/3082/feed"},
    {"name": "ğŸ‡®ğŸ‡± i24 News",           "url": "https://www.i24news.tv/en/rss"},
    {"name": "ğŸ‡®ğŸ‡± Arutz Sheva",        "url": "https://www.israelnationalnews.com/Rss.aspx/news"},
    {"name": "ğŸ‡®ğŸ‡· Iran International", "url": "https://www.iranintl.com/en/rss"},
    {"name": "ğŸ‡®ğŸ‡· Radio Farda",        "url": "https://www.radiofarda.com/api/zmqpqopvp"},
    {"name": "ğŸŒ Al-Monitor ME",       "url": "https://www.al-monitor.com/rss.xml"},
    {"name": "ğŸŒ Middle East Eye",     "url": "https://www.middleeasteye.net/rss"},
    {"name": "ğŸŒ Arab News",           "url": "https://www.arabnews.com/rss.xml"},
    {"name": "ğŸ” ISW",                 "url": "https://www.understandingwar.org/rss.xml"},
    {"name": "ğŸ” Long War Journal",    "url": "https://www.longwarjournal.org/feed"},
    {"name": "ğŸ” Bellingcat",          "url": "https://www.bellingcat.com/feed/"},
    {"name": "ğŸ” OSINT Defender",      "url": "https://osintdefender.com/feed/"},
    {"name": "ğŸ” Lawfare Blog",        "url": "https://www.lawfaremedia.org/feed"},
    {"name": "ğŸ” Foreign Policy",      "url": "https://foreignpolicy.com/feed/"},
    {"name": "ğŸ” Foreign Affairs",     "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "ğŸ” RAND Security",       "url": "https://www.rand.org/topics/defense-and-security.xml"},
    {"name": "ğŸ” Just Security",       "url": "https://www.justsecurity.org/feed/"},
]

GOOGLE_NEWS_QUERIES = [
    ("âš”ï¸ Iran Israel War",          "Iran Israel war attack strike today"),
    ("âš”ï¸ Iran Airstrike",           "Iran airstrike bomb explosion 2026"),
    ("âš”ï¸ US Iran Military",         "United States Iran military IRGC 2026"),
    ("âš”ï¸ IDF Operation",            "IDF military operation strike 2026"),
    ("âš”ï¸ Iran Nuclear 2026",        "Iran nuclear IAEA uranium enrichment 2026"),
    ("âš”ï¸ Iran Drone Missile",       "Iran ballistic missile drone attack"),
    ("âš”ï¸ Hezbollah IDF",            "Hezbollah IDF Lebanon border strike"),
    ("âš”ï¸ Strait Hormuz",            "Strait Hormuz tanker navy seized"),
    ("âš”ï¸ IRGC CENTCOM",             "IRGC Revolutionary Guard CENTCOM base"),
    ("âš”ï¸ Israel Airstrike",         "Israel F-35 airstrike Syria Iraq Iran"),
    ("âš”ï¸ Mossad CIA",               "Mossad CIA covert operation"),
    ("âš”ï¸ Khamenei Netanyahu",       "Khamenei Netanyahu war threat"),
    ("âš”ï¸ US Carrier Gulf",          "US carrier strike group Persian Gulf"),
    ("âš”ï¸ Iron Dome Intercept",      "Iron Dome Patriot Arrow intercept missile"),
    ("âš”ï¸ Iran Sanctions 2026",      "Iran sanctions 2026 oil SWIFT"),
    ("âš”ï¸ Red Sea Houthis",          "Red Sea Houthi attack ship missile"),
    ("âš”ï¸ Gaza Ceasefire 2026",      "Gaza ceasefire Hamas IDF deal 2026"),
    ("âš”ï¸ Iran Proxy Iraq",          "Iran proxy militia Iraq Syria US base attack"),
    ("âš”ï¸ DEFCON Nuclear",           "DEFCON nuclear military escalation"),
    ("âš”ï¸ Trump Iran Policy",        "Trump Iran Israel military policy 2026"),
]

def gnews(q): return f"https://news.google.com/rss/search?q={q.replace(' ','+')}&hl=en-US&gl=US&ceid=US:en&num=15"
GOOGLE_FEEDS = [{"name": n, "url": gnews(q), "is_google": True} for n, q in GOOGLE_NEWS_QUERIES]

TWITTER_ACCOUNTS = [
    ("ğŸ” OSINT Defender",      "OSINTdefender"),
    ("ğŸ” Intel Crab",          "IntelCrab"),
    ("ğŸ” War Monitor",         "WarMonitor3"),
    ("ğŸ” Conflicts.media",     "Conflicts"),
    ("ğŸ” Aurora Intel",        "AuroraIntel"),
    ("ğŸ” Jake Hanrahan",       "Jake_Hanrahan"),
    ("ğŸ” GeoConfirmed",        "GeoConfirmed"),
    ("ğŸ“° Axios: Barak Ravid",  "BarakRavid"),
    ("ğŸ“° Axios: Alex Ward",    "alexward1961"),
    ("ğŸ“° Axios: Zach Basu",    "ZachBasu"),
    ("ğŸ“° Reuters: Idrees Ali", "idreesali114"),
    ("ğŸ“° Reuters: Phil Stewart","phil_stewart_"),
    ("ğŸ“° NYT: Farnaz Fassihi", "farnazfassihi"),
    ("ğŸ“° NYT: Eric Schmitt",   "EricSchmittNYT"),
    ("ğŸ“° NYT: Helene Cooper",  "helenecooper"),
    ("ğŸ“° WaPo: Dan Lamothe",   "DanLamothe"),
    ("ğŸ“° Politico: Lara S",    "laraseligman"),
    ("ğŸ“° FP: Jack Detsch",     "JackDetsch"),
    ("ğŸ“° FP: Robbie Gramer",   "RobbieGramer"),
    ("ğŸ“° NatashaBertrand",     "NatashaBertrand"),
    ("ğŸ‡®ğŸ‡± IDF Official",       "IDF"),
    ("ğŸ‡®ğŸ‡± Yossi Melman",       "yossi_melman"),
    ("ğŸ‡®ğŸ‡± Seth Frantzman",     "sfrantzman"),
    ("ğŸ‡®ğŸ‡± Avi Issacharoff",    "AviIssacharoff"),
    ("ğŸ‡®ğŸ‡± Ben Caspit",         "BenCaspit"),
    ("ğŸ‡®ğŸ‡· Iran Intl English",  "IranIntl_En"),
    ("ğŸ‡®ğŸ‡· Radio Farda",        "RadioFarda_"),
    ("ğŸ‡ºğŸ‡¸ CENTCOM",            "CENTCOM"),
    ("ğŸ‡ºğŸ‡¸ Dept of Defense",    "DeptofDefense"),
    ("ğŸŒ Joyce Karam",         "Joyce_Karam"),
    ("ğŸŒ Ragip Soylu",         "ragipsoylu"),
    ("ğŸŒ Lindsey Snell",       "LindseySnell"),
    ("âš ï¸ DEFCON Level",        "DEFCONLevel"),
    ("âš ï¸ Arms Control Wonk",   "ArmsControlWonk"),
]

NITTER_MIRRORS = [
    "https://nitter.poast.org",
    "https://nitter.privacydev.net",
    "https://nitter.1d4.us",
    "https://nitter.kavin.rocks",
]

def get_twitter_feeds():
    return [{"name": f"ğ• {n}", "url": f"{NITTER_MIRRORS[0]}/{h}/rss",
             "nitter_handle": h, "nitter_mirrors": NITTER_MIRRORS}
            for n, h in TWITTER_ACCOUNTS]

ALL_FEEDS = RSS_FEEDS + GOOGLE_FEEDS + get_twitter_feeds()

KEYWORDS = [
    "Ø³Ù¾Ø§Ù‡","Ù…ÙˆØ´Ú©","Ø¬Ù†Ú¯","Ø­Ù…Ù„Ù‡","Ø§Ø³Ø±Ø§ÛŒÛŒÙ„","Ø¢Ù…Ø±ÛŒÚ©Ø§","Ø§ÛŒØ±Ø§Ù†","Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ","Ù¾Ù‡Ù¾Ø§Ø¯","Ù†Ø¸Ø§Ù…ÛŒ",
    "iran","irgc","khamenei","tehran","revolutionary guard","nuclear",
    "israel","idf","mossad","tel aviv","netanyahu","hamas","hezbollah","houthi",
    "pentagon","centcom","us forces","us military","us base","american",
    "strike","airstrike","missile","ballistic","drone","attack","bomb","explosion",
    "assassination","operation","warship","carrier","navy","air force",
    "persian gulf","strait of hormuz","red sea","middle east",
    "iron dome","arrow","patriot","hypersonic","uranium","enrichment","natanz","fordo",
    "intelligence","cia","covert","sanction","embargo",
    "gaza","west bank","lebanon","syria","iraq","yemen","bahrain",
    "trump","rubio","war","conflict","escalat","deploy","military",
]

def is_fresh(entry):
    """ÙÙ‚Ø· Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Û°Û³:Û±Û¸ ØªÙ‡Ø±Ø§Ù† Û²Û² ÙÙˆØ±ÛŒÙ‡ â€” Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡"""
    try:
        t = entry.get("published_parsed") or entry.get("updated_parsed")
        if not t:
            return False  # Ø®Ø¨Ø± Ø¨Ø¯ÙˆÙ† ØªØ§Ø±ÛŒØ® Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        dt = datetime(*t[:6], tzinfo=timezone.utc)
        return dt >= NEWS_CUTOFF
    except:
        return False  # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯

def is_relevant(entry, is_twitter=False):
    text = " ".join([str(entry.get("title","")), str(entry.get("summary","")),
                     str(entry.get("description",""))]).lower()
    if is_twitter:
        return any(k in text for k in ["iran","israel","idf","irgc","strike","war","attack",
                   "missile","drone","military","nuclear","hezbollah","hamas","houthi",
                   "centcom","pentagon","gaza","lebanon","tehran","netanyahu","khamenei"])
    return any(k in text for k in KEYWORDS)

async def fetch_one(client, cfg):
    handle = cfg.get("nitter_handle")
    mirrors = cfg.get("nitter_mirrors", []) if handle else []
    urls = [f"{m}/{handle}/rss" for m in mirrors] if mirrors else [cfg["url"]]
    for url in urls:
        try:
            r = await client.get(url, timeout=httpx.Timeout(10.0),
                                 headers={"User-Agent": "Mozilla/5.0 MilNewsBot/8.0"})
            if r.status_code == 200:
                entries = feedparser.parse(r.text).entries
                if entries: return entries
        except: pass
    return []

async def fetch_all(client):
    results = await asyncio.gather(*[fetch_one(client, cfg) for cfg in ALL_FEEDS], return_exceptions=True)
    out = []
    for i, res in enumerate(results):
        if isinstance(res, list):
            for entry in res:
                out.append((entry, ALL_FEEDS[i]))
    return out

GEMINI_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"

async def translate(client, title, summary):
    """ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ â€” Ù‡Ø± Ø²Ø¨Ø§Ù†ÛŒ (Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ø¹Ø¨Ø±ÛŒØŒ Ø¹Ø±Ø¨ÛŒØŒ ...) â†’ ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ø®Ø¨Ø±ÛŒ"""
    if not GEMINI_API_KEY or len(title) < 3:
        return title, summary

    prompt = f"""ÙˆØ¸ÛŒÙÙ‡: ØªØ±Ø¬Ù…Ù‡ Ø¯Ù‚ÛŒÙ‚ Ø®Ø¨Ø± Ù†Ø¸Ø§Ù…ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
Ø²Ø¨Ø§Ù† ÙˆØ±ÙˆØ¯ÛŒ: Ù‡Ø± Ø²Ø¨Ø§Ù†ÛŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª (Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ø¹Ø¨Ø±ÛŒØŒ Ø¹Ø±Ø¨ÛŒØŒ ...)
Ø®Ø±ÙˆØ¬ÛŒ: ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ùˆ Ø®Ø¨Ø±ÛŒ â€” Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† ØªÙˆØ¶ÛŒØ­ØŒ Ù¾Ø±Ø§Ù†ØªØ²ØŒ ÛŒØ§ Ø­Ø§Ø´ÛŒÙ‡

Ù‚ÙˆØ§Ù†ÛŒÙ† Ø³Ø®Øª:
Û±. ÙÙ‚Ø· ØªØ±Ø¬Ù…Ù‡ Ø¨Ù†ÙˆÛŒØ³
Û². Ø§Ø³Ø§Ù…ÛŒ Ø®Ø§Øµ Ø±Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø± (Ù†ØªØ§Ù†ÛŒØ§Ù‡ÙˆØŒ Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒØŒ Ø³Ù¾Ø§Ù‡ØŒ Ù†Ø§ØªÙˆ...)
Û³. Ù„Ø­Ù† Ø±Ø³Ù…ÛŒ Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´
Û´. Ø§Ú¯Ø± Ø¬Ù…Ù„Ù‡â€ŒØ§ÛŒ Ù†Ø§Ù‚Øµ Ø§Ø³ØªØŒ Ú©Ø§Ù…Ù„ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†

ÙØ±Ù…Øª Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹:
Ø¹Ù†ÙˆØ§Ù†: [ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†ÙˆØ§Ù†]
---
Ù…ØªÙ†: [ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ†]

===ÙˆØ±ÙˆØ¯ÛŒ===
Ø¹Ù†ÙˆØ§Ù†: {title[:500]}
Ù…ØªÙ†: {summary[:800]}"""

    for attempt in range(2):
        try:
            r = await client.post(
                f"{GEMINI_URL}?key={GEMINI_API_KEY}",
                json={
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {"temperature": 0.05, "maxOutputTokens": 1200}
                },
                timeout=httpx.Timeout(25.0)
            )
            if r.status_code == 200:
                raw = r.json()["candidates"][0]["content"]["parts"][0]["text"].strip()
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø®Ø±ÙˆØ¬ÛŒ
                raw = re.sub(r'^Ø¹Ù†ÙˆØ§Ù†:\s*', '', raw, flags=re.MULTILINE)
                raw = re.sub(r'^Ù…ØªÙ†:\s*', '', raw, flags=re.MULTILINE)
                parts = raw.split("---", 1)
                if len(parts) == 2:
                    fa_t = normalize_fa(parts[0].strip().replace("**",""))
                    fa_s = normalize_fa(parts[1].strip().replace("**",""))
                    return fa_t, fa_s
                else:
                    return normalize_fa(raw.strip()), ""
            elif r.status_code == 429:
                wait = int(r.headers.get("Retry-After", 15))
                log.warning(f"â³ Gemini rate limit â€” {wait}s")
                await asyncio.sleep(wait)
            elif r.status_code == 503:
                await asyncio.sleep(5)
            else:
                log.debug(f"Gemini {r.status_code}")
                break
        except Exception as e:
            log.debug(f"Gemini: {e}")
            if attempt == 0:
                await asyncio.sleep(3)

    return title, summary  # fallback: Ù…ØªÙ† Ø§ØµÙ„ÛŒ

def clean_html(text):
    if not text: return ""
    return BeautifulSoup(str(text), "html.parser").get_text(" ", strip=True)

def make_id(entry):
    """ID Ø§ØµÙ„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù„ÛŒÙ†Ú©"""
    key = entry.get("link") or entry.get("id") or entry.get("title") or ""
    return hashlib.md5(key.encode("utf-8")).hexdigest()

def make_title_id(title: str) -> str:
    """ID Ø«Ø§Ù†ÙˆÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù†ÙˆØ§Ù† â€” Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø¨Ø± ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù"""
    # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù†ÙˆØ§Ù† Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡
    t = re.sub(r'[^a-z0-9\u0600-\u06FF]', '', title.lower())
    return "t:" + hashlib.md5(t.encode("utf-8")).hexdigest()

def format_dt(entry):
    try:
        t = entry.get("published_parsed") or entry.get("updated_parsed")
        if t:
            return datetime(*t[:6], tzinfo=timezone.utc).astimezone(TEHRAN_TZ).strftime("ğŸ• %H:%M  |  ğŸ“… %Y/%m/%d")
    except: pass
    return ""

def esc(t): return (t or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")
def trim(t, n=700): t=re.sub(r'\s+',' ',t).strip(); return t if len(t)<=n else t[:n].rsplit(" ",1)[0]+"â€¦"

def load_seen():
    if Path(SEEN_FILE).exists():
        try:
            with open(SEEN_FILE) as f: return set(json.load(f))
        except: pass
    return set()

def save_seen(seen):
    with open(SEEN_FILE,"w") as f: json.dump(list(seen)[-10000:], f)

TGAPI = f"https://api.telegram.org/bot{BOT_TOKEN}"

async def tg_send(client, text):
    for _ in range(4):
        try:
            r = await client.post(f"{TGAPI}/sendMessage", json={
                "chat_id": CHANNEL_ID, "text": text[:MAX_MSG_LEN],
                "parse_mode": "HTML", "disable_web_page_preview": True,
            }, timeout=httpx.Timeout(15.0))
            data = r.json()
            if data.get("ok"): return True
            if data.get("error_code") == 429:
                await asyncio.sleep(data.get("parameters",{}).get("retry_after",15))
            elif data.get("error_code") in (400, 403):
                log.error(f"TG fatal: {data.get('description')}"); return False
            else: await asyncio.sleep(5)
        except Exception as e:
            log.warning(f"TG: {e}"); await asyncio.sleep(8)
    return False

async def main():
    if not BOT_TOKEN or not CHANNEL_ID:
        log.error("âŒ BOT_TOKEN ÛŒØ§ CHANNEL_ID ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡!"); return

    seen = load_seen()
    tehran_cutoff = NEWS_CUTOFF.astimezone(TEHRAN_TZ).strftime("%Y/%m/%d %H:%M")
    log.info(f"ğŸš€ {len(ALL_FEEDS)} Ù…Ù†Ø¨Ø¹ | {len(seen)} Ø¯Ø± Ø­Ø§ÙØ¸Ù‡")
    log.info(f"ğŸ“… Cutoff: {tehran_cutoff} ØªÙ‡Ø±Ø§Ù† (ÙÙ‚Ø· Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ†)")

    async with httpx.AsyncClient(follow_redirects=True) as client:
        raw = await fetch_all(client)
        log.info(f"ğŸ“¥ {len(raw)} Ø¢ÛŒØªÙ… Ø¯Ø±ÛŒØ§ÙØª â€” ÙÛŒÙ„ØªØ±...")

        collected = []
        title_seen = set()  # dedup Ø§Ø¶Ø§ÙÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù†ÙˆØ§Ù† â€” Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø¨Ø± ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø² Ú†Ù†Ø¯ Ù…Ù†Ø¨Ø¹
        for entry, cfg in raw:
            eid = make_id(entry)
            if eid in seen: continue
            if not is_fresh(entry): seen.add(eid); continue
            is_tw = bool(cfg.get("nitter_handle"))
            if not is_relevant(entry, is_twitter=is_tw): seen.add(eid); continue
            # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù† Ø¹Ù†ÙˆØ§Ù†
            raw_title = clean_html(entry.get("title",""))
            tid = make_title_id(raw_title)
            if tid in title_seen: seen.add(eid); continue
            title_seen.add(tid)
            collected.append((eid, entry, cfg, is_tw))

        collected = list(reversed(collected))
        if len(collected) > MAX_NEW_PER_RUN:
            collected = collected[-MAX_NEW_PER_RUN:]

        log.info(f"âœ… {len(collected)} Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯")
        sent = 0

        for eid, entry, cfg, is_tw in collected:
            en_title  = trim(clean_html(entry.get("title","")), 300)
            en_sum    = trim(clean_html(entry.get("summary") or entry.get("description") or ""), 700)
            link      = entry.get("link","")
            dt        = format_dt(entry)

            log.info(f"ğŸ”„ {en_title[:50]}...")
            fa_title, fa_sum = await translate(client, en_title, en_sum)

            icon = "ğ•" if is_tw else "ğŸ“¡"
            lines = [f"ğŸ”´ <b>{esc(fa_title)}</b>", ""]
            if fa_sum and len(fa_sum)>10 and fa_sum.lower() not in fa_title.lower():
                lines += [esc(fa_sum), ""]
            lines += ["â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€", f"ğŸ“Œ <i>{esc(en_title)}</i>"]
            if dt: lines.append(dt)
            lines.append(f"{icon} <b>{cfg['name']}</b>")
            if link: lines.append(f'ğŸ”— <a href="{link}">Ù…Ù†Ø¨Ø¹</a>')

            if await tg_send(client, "\n".join(lines)):
                seen.add(eid); sent += 1; log.info("  âœ…")
            else:
                log.error("  âŒ")
            await asyncio.sleep(SEND_DELAY)

        save_seen(seen)
        log.info(f"ğŸ {sent}/{len(collected)} Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")

if __name__ == "__main__":
    asyncio.run(main())
